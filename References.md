# Libraries

-   Anomalib: https://github.com/openvinotoolkit/anomalib :white\_check\_mark:
-   Pyod : https://pyod.readthedocs.io/en/latest/ :white\_check\_mark:

# Reference

\[1\] \[2\] \[3\] \[4\] \[5\] \[6\] \[7\] \[8\] \[9\] \[10\] \[11\] \[12\] \[13\] \[14\] \[15\] \[16\] \[17\] \[18\] \[19\] \[20\] \[21\] \[22\] \[23\] \[24\] \[25\] \[26\] \[27\] \[28\]

[1]

[2]

<span class="csl-left-margin">\[3\] </span><span class="csl-right-inline">Andrew ng. (2006). [Machine Learning : Regression and Classification]({https://see.stanford.edu/Course/CS229}), Stanford</span>

<span class="csl-left-margin">\[4\] </span><span class="csl-right-inline">Guillaume Saint-Cirgue. (2019). [Apprendre machine learning]({https://machinelearnia.com/apprendre-le-machine-learning-en-une-semaine}), London</span>

<span class="csl-left-margin">\[5\] </span><span class="csl-right-inline">Jason Brownlee. (2019). [A Gentle Introduction to Uncertainty in Machine Learning]({https://machinelearningmastery.com/uncertainty-in-machine-learning})</span>

<span class="csl-left-margin">\[6\] </span><span class="csl-right-inline">Gareth James, Daniela Witten, Trevor Hastie and Rob Tibshirani. (2014). [An Introduction to Statistical Learning]({https://www.statlearning.com})</span>

<span class="csl-left-margin">\[7\] </span><span class="csl-right-inline">Gilbert Saporta. (2011). [Probabilités, analyse des données et statistique]({http://www.editionstechnip.com/en/catalogue-detail/149/probabilites-analyse-des-donnees-et-statistique.html})</span>

<span class="csl-left-margin">\[8\] </span><span class="csl-right-inline">Wikipedia-Probabilité. (2021). [Probabilité totale]({https://fr.wikipedia.org/wiki/Formule_des_probabilités_totales})</span>

<span class="csl-left-margin">\[9\] </span><span class="csl-right-inline">Wikipedia-Integrated Circuit. (2023). [Nombre de transistor par micropuce]({https://en.wikipedia.org/wiki/Transistor_count})</span>

<span class="csl-left-margin">\[10\] </span><span class="csl-right-inline">I-Scoop. (2021). [Evolution du volume de donnée stockée dans le monde, par an]({https://www.i-scoop.eu/big-data-action-value-context/data-age-2025-datasphere})</span>

<span class="csl-left-margin">\[11\] </span><span class="csl-right-inline">Wikipedia-Machine Learning. (2021). [Kernel Ridge Regression]({https://en.wikipedia.org/wiki/Kernel_embedding_of_distributions})</span>

<span class="csl-left-margin">\[12\] </span><span class="csl-right-inline">Wikipedia-Machine Learnng. (2021). [K-Nearest Neighbor]({https://fr.wikipedia.org/wiki/Méthode_des_k_plus_proches_voisins})</span>

<span class="csl-left-margin">\[13\] </span><span class="csl-right-inline">Wikipedia-Analyse. (2021). [Spline]({https://fr.wikipedia.org/wiki/Spline})</span>

<span class="csl-left-margin">\[14\] </span><span class="csl-right-inline">Wikipedia-Informatique théorique. (2021). [Boosting]({https://fr.wikipedia.org/wiki/Boosting})</span>

<span class="csl-left-margin">\[15\] </span><span class="csl-right-inline">Wikipedia-Informatique théorique. (2021). [Estimateur du maximum de vraisemblance]({https://fr.wikipedia.org/wiki/Maximum_de_vraisemblance})</span>

<span class="csl-left-margin">\[16\] </span><span class="csl-right-inline">Wikipedia-Probabilité. (2022). [Modèle linéaire]({https://fr.wikipedia.org/wiki/Modèle_linéaire})</span>

<span class="csl-left-margin">\[17\] </span><span class="csl-right-inline">Wikipedia-Probabilité. (2022). [Régression polynomiale]({https://fr.wikipedia.org/wiki/Régression_polynomiale})</span>

<span class="csl-left-margin">\[18\] </span><span class="csl-right-inline">Samuel Ieong. (2006). [Probability Theory Review for Machine Learning]({https://see.stanford.edu/materials/aimlcs229/cs229-prob.pdf}), Stanford</span>

<span class="csl-left-margin">\[19\] </span><span class="csl-right-inline">Zico Kolter. (2007). [Linear Algebra Review and Reference]({https://see.stanford.edu/materials/aimlcs229/cs229-linalg.pdf}), Stanford</span>
