# [2. L'apprentissage statistique](#section2) #

[Retour README](../README.md)

<a name="toc"/>

[toc]

<a name="2-1"/>

## [2.1 Qu'est-ce que l'apprentissage statistique?](#2-1) ##

[Retour TOC](#toc)

[[6](https://www.statlearning.com/)] Afin de motiver notre √©tude de l'apprentissage statistique, nous commen√ßons par un exemple simple. Supposons que nous soyons des consultants en statistiques engag√©s par un client pour √©tudier l'association entre la publicit√© et les ventes d'un produit particulier. 

L'ensemble de donn√©es sur la publicit√© est constitu√© 

1. des ventes de ce produit sur 200 march√©s diÔ¨Ä√©rents, ainsi que 
2. des budgets publicitaires du produit sur chacun de ces march√©s via trois m√©dias diÔ¨Ä√©rents : TV, radio, et journaux. 

Ces donn√©es sont pr√©sent√©es √† la $figure\ 2.1$. 

<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 70%;"
    src="../images/Marketing_pub.png" 
    alt="Moore's law">
</img>

<b>FIG 2.1</b><i> ![L'ensemble de donn√©es sur la publicit√©. Le graphique pr√©sente les ventes, en milliers d'unit√©s, en fonction des budgets de la t√©l√©vision, de la radio et des journaux, en milliers de dollars, pour 200 march√©s diÔ¨Ä√©rents. Dans chaque graphique, nous montrons l‚Äôajustement simple des moindres carr√©s des ventes √† cette variable, comme d√©crit dans la section 4. En d'autres termes, chaque ligne bleue repr√©sente un mod√®le simple qui peut √™tre utilis√© pour pr√©dire les ventes duent aux publicit√©s via la t√©l√©vision, la radio et le journal.](https://www.statlearning.com)</i>

Il n'est pas possible pour notre client d'augmenter directement les ventes du produit. En revanche, il peut contr√¥ler les d√©penses publicitaires dans chacun de ces trois m√©dias. 

Par cons√©quent, si nous d√©terminons qu'il existe une association entre la publicit√© et les ventes, nous pouvons demander √† notre client d'ajuster les budgets publicitaires, augmentant ainsi indirectement les ventes. En d'autres termes, notre objectif est de d√©velopper un mod√®le pr√©cis qui puisse √™tre utilis√© pour pr√©dire les ventes sur la base du budget des trois m√©dias.

Dans ce contexte, les budgets publicitaires sont des variables d'entr√©e tandis que les ventes sont une variable de sortie. 

**Les variables d'entr√©e** sont g√©n√©ralement d√©sign√©es par le symbole $X$, avec un indice pour les distinguer. Ainsi, $X_1$ pourrait √™tre le budget de la t√©l√©vision, $X_2$ celui de la radio et $X_3$ celui des journaux. **Les entr√©es portent des noms** diÔ¨Ä√©rents, tels que **pr√©dicteurs**, **variables ind√©pendantes**, **caract√©ristiques (features)**, ou parfois juste variables.

**La variable de sortie** - dans ce cas, les ventes - est souvent **appel√©e la r√©ponse** ou **la variable d√©pendante**, et est g√©n√©ralement d√©sign√©e par le symbole $Y$ . 

Plus g√©n√©ralement, supposons que nous observions une r√©ponse quantitative $Y$ et $p$ pr√©dicteurs diÔ¨Ä√©rents, $X_1,X_2,..., X_p$. Nous supposons qu'il existe une relation entre $Y$ et $X=\ (X_1,X_2,...,X_p)$, qui peut s'√©crire sous la forme tr√®s g√©n√©rale suivante $\boxed{Y=f(X)+\ \epsilon}$.

Ici, $f$ est une certaine fonction Ô¨Åx√©e mais inconnue de $X_1,...,X_p$, avec $\varepsilon$ e qui est un terme d'erreur al√©atoire,  ind√©pendant de $X$ et qui a une moyenne de z√©ro. 

Dans cette formule, $f$ repr√©sente l'information syst√©matique que $X$ fournit sur $Y$ .

<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 70%;"
    src="../images/Ensemble_donnees_sur_revenus.png" 
    alt="Moore's law">
</img>

<b>FIG 2.2</b><i> ![L'ensemble de donn√©es sur le revenu. A Gauche : Les points rouges repr√©sentent les valeurs observ√©es du revenu (en dizaines de milliers de dollars) et des ann√©es d'√©tudes pour 30 individus. A Droite. : La courbe bleue repr√©sente la v√©ritable relation sous-jacente entre le revenu et les ann√©es d'√©tudes, qui est g√©n√©ralement inconnue (mais qui est connue dans ce cas car les donn√©es ont √©t√© simul√©es). Les lignes noires repr√©sentent l'erreur associ√©e √† chaque observation. Notez que certaines erreurs sont positives (si une observation se situe au-dessus de la courbe bleue) et d'autres sont n√©gatives (si une observation se situe en dessous de la courbe). Globalement, ces erreurs ont une moyenne approximative de z√©ro.](https://www.statlearning.com)</i>

Prenons un autre exemple, celui du panneau de gauche de la $figure\ 2.2$, un graphique du revenu en fonction du nombre d'ann√©es d'√©tudes de 30 individus. Le graphique sugg√®re que l'on pourrait √™tre en mesure de pr√©dire le revenu √† l'aide du nombre d'ann√©es d'√©tudes. Cependant, la fonction $f$ qui relie la variable d'entr√©e √† la variable de sortie est en g√©n√©ral inconnue. 

Dans cette situation, on doit estimer $f$ sur la base des points observ√©s. Puisque le revenu est un ensemble de donn√©es simul√©es, $f$ est connu et est repr√©sent√© par la courbe bleue dans le panneau de droite de la $figure\ 2.2$. 

Les lignes verticales repr√©sentent les termes d'erreur $\boldsymbol\varepsilon$. Nous remarquons que certaines des 30 observations se situent au-dessus de la courbe bleue et d'autres en dessous (dans l'ensemble, les erreurs ont approximativement la moyenne √©gale √† z√©ro). 

En g√©n√©ral, la fonction $f$ peut impliquer plus d'une variable d'entr√©e. 

<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 50%;"
    src="../images/Revenu_Fonction_Annee_Etude_Anciennete.png" 
    alt="Moore's law">
</img>

<b>FIG 2.3</b><i> ![Le graphique repr√©sente le revenu en fonction des ann√©es d'√©tudes et de l'anciennet√©. La surface bleue repr√©sente la v√©ritable relation non d√©duite entre le revenu et les ann√©es d'√©tudes et l'anciennet√©, qui est connue puisque les donn√©es sont simul√©es. Les points rouges indiquent les valeurs observ√©es de ces quantit√©s pour 30 individus.](https://www.statlearning.com/)</i>

Dans la $figure\ 2.3$, nous repr√©sentons le revenu en fonction des ann√©es d'√©tudes et de l'anciennet√©. Ici, $f$ est une surface bidimensionnelle qui doit √™tre estim√©e sur la base des donn√©es observ√©es.

Par essence, l'apprentissage statistique fait r√©f√©rence √† un ensemble d'approches permettant d'estimer $f$. 

Dans cette section, nous pr√©sentons certains des concepts th√©oriques cl√©s qui interviennent dans l'estimation de $f$, ainsi que des outils permettant d'√©valuer les estimations obtenues.

<a name="2-1-1"/>

### [2.1.1 Pourquoi estimer f ?](#2-1-1) ###

[Retour TOC](#toc)

Il y a deux raisons principales pour lesquelles nous pouvons souhaiter estimer $f$ : **la pr√©diction** et **l'inf√©rence**. Nous les abordons tour √† tour.

<a name="2-1-1-1"/>

#### [2.1.1.1 Pr√©diction](#2-1-1-1) ####

[Retour TOC](#toc)

Dans de nombreuses situations, un ensemble d'entr√©es $X$ est facilement disponible, mais la sortie $Y$ ne peut pas √™tre facilement obtenue. Dans ce cas, puisque le terme d'erreur est en moyenne √©gal √† z√©ro, nous pouvons pr√©dire $Y$ en utilisant

$$
\boxed{\hat{Y}=\hat{f}(X)}
$$

o√π  **$\hat{f}$ repr√©sente notre estimation de $f$**, et **$\hat{Y}$ repr√©sente la pr√©diction r√©sultante pour $Y$** . **Dans ce contexte, $\hat{f}$ est souvent trait√© comme une bo√Æte noire**, dans le sens o√π l'on ne se pr√©occupe g√©n√©ralement pas de la forme exacte de l'expression $\hat{f}$, √† condition qu'elle donne des pr√©dictions pr√©cises pour $Y$ .

√Ä titre d'exemple, supposons que $X_1,...,X_p$ soient des caract√©ristiques (features) sur un √©chantillon de sang d'un patient, qui peuvent √™tre facilement mesur√©es en laboratoire, et que $Y$ soit une variable codant le risque pour le patient de subir une r√©action ind√©sirable grave √† un m√©dicament particulier.
Il est naturel de chercher √† pr√©dire $Y$ √† l'aide de $X$, puisque nous pouvons alors √©viter de donner le m√©dicament en question aux patients qui pr√©sentent un risque √©lev√© d'effet ind√©sirable, c'est-√†-dire aux patients pour lesquels l'estimation de $Y$ est √©lev√©e.

**La pr√©cision de $\hat{Y}$ comme une pr√©diction pour $Y$ d√©pend de deux quantit√©s**, que nous appellerons **l'erreur r√©ductible** et **l'erreur irr√©ductible**. 

En g√©n√©ral, **$\hat{f}$ ne sera pas une estimation parfaite de $f$,** et cette impr√©cision introduira une certaine erreur. **Cette erreur est r√©ductible parce que nous pouvons potentiellement am√©liorer la pr√©cision de $\hat{f}$ en utilisant la technique d'apprentissage statistique la plus appropri√©e pour estimer $f$**. 

Cependant, m√™me s'il √©tait possible de former une estimation parfaite de $f$, de sorte que notre r√©ponse estim√©e prenne la forme  $\hat{Y}=f(X)$, notre pr√©diction comporterait toujours une certaine erreur ! En effet, $Y$ est √©galement une fonction de $\boldsymbol\varepsilon$, qui par d√©finition ne peut √™tre pr√©dite √† l'aide de $X$. Par cons√©quent, la variabilit√© associ√©e √† $\boldsymbol\varepsilon$ affectera √©galement la pr√©cision de nos pr√©dictions. C'est ce qu'on appelle **l'erreur irr√©ductible, car quelle que soit la qualit√© de notre estimation de $f$, nous ne pouvons pas r√©duire l'erreur introduite par $\boldsymbol\varepsilon$**.

***Pourquoi l'erreur irr√©ductible est-elle sup√©rieure √† z√©ro ?*** 
La quantit√© $\boldsymbol\varepsilon$ peut contenir des variables non mesur√©es qui sont utiles pour pr√©dire $Y$ : puisque nous ne les mesurons pas, $f$ ne peut pas les utiliser pour sa pr√©diction. La quantit√© $\varepsilon$ peut √©galement contenir des variations non mesurables. 
Par exemple, le risque d'un effet ind√©sirable peut varier pour un patient donn√©, un jour donn√©, en fonction de la variation de fabrication du m√©dicament lui-m√™me ou du sentiment g√©n√©ral de bien-√™tre du patient ce jour-l√†.

Consid√©rons une estimation donn√©e $\hat{f}$ et un ensemble de pr√©dicteurs $X$, qui donne la pr√©diction $\hat{Y}=\hat{f}(X)$ . Supposons un instant que $\hat{f}$ et $X$ sont tous deux fix√©s, de sorte que la seule variabilit√© provient de $\boldsymbol\varepsilon$. Alors, il est facile de montrer que

$$
E(Y-\hat Y)^2 = E[f(X) + \varepsilon -\hat f(X)]^2 
$$

$$
\hspace{8.5em}= E[f(X) -\hat f(X)]^2 + VAR(\varepsilon) ,
$$

avec $E[f(X) -\hat f(X)]^2$ l'**erreur r√©ductible** et $VAR(\varepsilon)$ **l'erreur irr√©ductible**.

Nous avons $E(Y- \hat Y)^2$ qui repr√©sente **la moyenne** (ou valeur attendue) **du carr√© de la diff√©rence entre la valeur pr√©dite et la valeur r√©elle de $ùëå$** , et $ùëâùëéùëü(ùúñ)$ qui **repr√©sente la variance associ√©e au terme d'erreur $\boldsymbol\varepsilon$** (mesure la dispersions des √©chantillons autour de la moyenne associ√©es √† l'erreur irr√©ductible). 

**Nous nous concentrons sur les techniques d'estimation de $ùëì$ dans le but de minimiser l'erreur r√©ductible**. Il est important de garder √† l'esprit que **l'erreur irr√©ductible fournira toujours une limite sup√©rieure √† la pr√©cision de notre pr√©diction pour $ùëå$** . Cette limite est presque toujours inconnue dans la pratique.

<a name="2-1-1-2"/>

#### [2.1.1.2 Inf√©rence](#2-1-1-2) ####

[Retour TOC](#toc)

Nous sommes souvent int√©ress√©s par la compr√©hension de l'association entre $Y$ et $X_1,...,X_p$. Dans cette situation, nous souhaitons estimer $f$, mais notre objectif n'est pas uniquement de faire des pr√©dictions pour $Y$ , et donc $\hat{f}$ ne peut pas √™tre trait√©e comme une bo√Æte noire, car nous devons conna√Ætre sa forme exacte. Dans ce cadre, on peut √™tre int√©ress√© √† r√©pondre aux questions suivantes.

***Quels pr√©dicteurs sont associ√©s √† la r√©ponse ?*** 
Il arrive souvent que seule une petite fraction des pr√©dicteurs disponibles soit substantiellement associ√©e √† $Y$ . Identifier les quelques pr√©dicteurs importants parmi un large ensemble de variables possibles peut √™tre extr√™mement utile, selon l'application.

***Quelle est la relation entre la r√©ponse et chaque pr√©dicteur ?*** 
Certains pr√©dicteurs peuvent avoir une relation positive avec $Y$ , en ce sens que des valeurs plus √©lev√©es du pr√©dicteur sont associ√©es √† des valeurs plus √©lev√©es de $Y$ . D'autres pr√©dicteurs peuvent avoir une relation inverse. Selon la complexit√© de $f$ , la relation entre la r√©ponse et un pr√©dicteur donn√© peut √©galement d√©pendre des valeurs des autres pr√©dicteurs. 

**La relation entre $Y$ et chaque pr√©dicteur peut-elle √™tre r√©sum√©e de mani√®re ad√©quate √† l'aide d'une √©quation lin√©aire, ou la relation est-elle plus compliqu√©e ?** 
Historiquement, la plupart des m√©thodes d'estimation de $f$ ont pris une forme lin√©aire. Dans certaines situations, une telle hypoth√®se est raisonnable ou m√™me souhaitable. Mais souvent, la relation r√©elle est plus compliqu√©e, auquel cas un mod√®le lin√©aire peut ne pas fournir une repr√©sentation pr√©cise de la relation entre les variables d'entr√©e et de sortie.

Nous verrons un certain nombre d'exemples qui rel√®vent du cadre de la pr√©diction, de l'inf√©rence ou d'une combinaison des deux.

<a name="2-1-1-3"/>

#### [2.1.1.3 Exemple sur la pr√©diction et l'inf√©rence](#2-1-1-3) ####

[Retour TOC](#toc)

Prenons l'exemple d'une entreprise qui souhaite mener une campagne de marketing direct. L'objectif est d'identifier les individus qui sont susceptibles de r√©pondre positivement √† un mailing, en se basant sur l'observation de variables d√©mographiques mesur√©es sur chaque individu. Dans ce cas, les variables d√©mographiques servent de pr√©dicteurs, et la r√©ponse √† la campagne de marketing (positive ou n√©gative) sert de r√©sultat. 

1. Soit, l'entreprise n'est pas int√©ress√©e par l'obtention d'une compr√©hension profonde des relations entre chaque pr√©dicteur individuel et la r√©ponse. Elle veut simplement pr√©dire avec pr√©cision la r√©ponse en utilisant les pr√©dicteurs. **Il s'agit d'un exemple de mod√©lisation pour la pr√©diction**.

2. En revanche, consid√©rons les donn√©es publicitaires illustr√©es √† la $figure\ 2.1$. On peut souhaiter r√©pondre √† des questions telles que :

   - ‚Äã	Quels m√©dias sont associ√©s aux ventes ?
   - ‚Äã	Quels sont les m√©dias qui g√©n√®rent la plus forte augmentation des ventes ? ou
   - ‚Äã	Quelle est l'ampleur de l'augmentation des ventes associ√©e √† une augmentation donn√©e de la publicit√© t√©l√©vis√©e ?

   Cette situation rel√®ve du paradigme de l'inf√©rence

Un autre exemple consiste √† mod√©liser la marque d'un produit qu'un client pourrait acheter en fonction de variables telles que le prix, l'emplacement du magasin, les niveaux de remise, le prix de la concurrence, etc. Dans cette situation, on pourrait vraiment s'int√©resser √† l'association entre chaque variable et la probabilit√© d'achat. Par exemple, dans quelle mesure le prix du produit est-il associ√© aux ventes ? **Il s'agit d'un exemple de mod√©lisation pour l'inf√©rence.**

Enfin, certaines mod√©lisations peuvent √™tre effectu√©es **√† la fois pour la pr√©diction et l'inf√©rence**. Par exemple, dans un contexte immobilier, on peut chercher √† relier la valeur des maisons √† des donn√©es telles que le taux de criminalit√©, le zonage, la distance par rapport √† une rivi√®re, la qualit√© de l'air, les √©coles, le niveau de revenu de la communaut√©, la taille des maisons, etc. Dans ce cas, on peut s'int√©resser √† l'association entre chaque variable d'entr√©e individuelle et le prix du logement - par exemple, quelle sera la valeur suppl√©mentaire d'une maison si elle a une vue sur la rivi√®re ? I**l s'agit d'un probl√®me d'inf√©rence**. On peut aussi simplement s'int√©resser √† la pr√©diction de la valeur d'une maison en fonction de ses caract√©ristiques : cette maison est-elle sous- ou sur-√©valu√©e ? **Il s'agit d'un probl√®me de pr√©diction**.

Selon que notre objectif ultime est la pr√©diction, l'inf√©rence ou une combinaison des deux, diÔ¨Ä√©rentes m√©thodes d'estimation de $f$ peuvent √™tre appropri√©es ;

- **les mod√®les lin√©aires** permettent **une inf√©rence relativement simple** et interpr√©table, mais peuvent **ne pas donner des pr√©dictions aussi pr√©cises** que certaines autres approches. 
- En revanche, certaines **des approches hautement non lin√©aires** que nous abordons dans les derni√®res sections peuvent potentiellement **fournir des pr√©dictions assez pr√©cises pour $Y$,** mais cela se fait au prix d'un mod√®le moins interpr√©table pour lequel **l'inf√©rence est plus difficile**.

<a name="2-1-2"/>

### [2.1.2 Comment estimer f ?](#2-1-2) ###

[Retour TOC](#toc)

Nous explorons de nombreuses approches lin√©aires et non lin√©aires pour estimer $f$. Cependant, ces m√©thodes partagent g√©n√©ralement certaines caract√©ristiques communes. Nous supposerons toujours que nous avons observ√© un ensemble de $n$ points de donn√©es diff√©rentes. Par exemple, dans la $figure\ 2.2$, nous avons observ√© $n=30$ points de donn√©es. **Ces observations sont appel√©es donn√©es d'apprentissage** parce que nous allons les utiliser pour entra√Æner, ou apprendre, √† notre m√©thode comment estimer $f$. 

Les donn√©es $x_{ij}$  repr√©sentent la valeur du $j^{√®me}$ pr√©dicteur (ou entr√©e) pour l'observation $i$, o√π $i=1,\ 2,...,n$ et $j=1,\ 2,...,p$. 

Par cons√©quent, $y_i$ repr√©sente la variable de r√©ponse pour la $i^{√®me}$ observation et nos donn√©es d'apprentissage consistent alors en ${(x_1,y_1),\ (x_2,y_2),...,\ (x_n,y_n)}$ o√π $x_i\ =\left(x_{i1},x_{i2},...,x_{ip}\right)^T $. 

**Notre objectif est d'appliquer une m√©thode d'apprentissage statistique aux donn√©es d'apprentissage afin d'estimer la fonction inconnue $f$**. 
En d'autres termes, nous voulons trouver une fonction $\hat{f}$ telle que $Y\approx\hat{f}(X)$ pour toute observation $(X,\ Y)$. 

**De mani√®re g√©n√©rale, la plupart des m√©thodes d'apprentissage statistique pour cette t√¢che peuvent √™tre caract√©ris√©es comme √©tant param√©triques ou non-param√©triques.** 

<a name="2-1-2-1"/>

#### [2.1.2.1 M√©thodes param√©triques](#2-1-2-1) ####

[Retour TOC](#toc)

Les m√©thodes param√©triques impliquent une approche bas√©e sur un mod√®le en deux √©tapes.

1. **Premi√®rement, nous faisons une hypoth√®se sur la forme fonctionnelle (ou forme) de $f$**. Par exemple, une hypoth√®se tr√®s simple est que f est lin√©aire en $X$ : 

$$
f\left(X\right)=\beta_0+\beta_1X_1+\beta_2X_2\ldots+\beta_pX_p.\hspace{6em}(2.1)
$$

$\hspace{2 em}$Il s'agit d'un mod√®le lin√©aire. D√®s que nous avons suppos√© que $f$ est lin√©aire, le probl√®me de l'estimation de $f$ est grandement simplifi√©. 

$\hspace{2 em}$Au lieu de devoir estimer une fonction $f(X)$ qui est $p{-}dimensionnelle$ enti√®rement arbitraire , il suffit d'estimer les $p+1$ 

$\hspace{2 em}$coefficients $\beta_0,\beta_1, . . . ,\beta_p$. 

2. Apr√®s avoir s√©lectionn√© un mod√®le, **nous avons besoin d'une proc√©dure qui utilise les donn√©es d'apprentissage pour ajuster ou entra√Æner le mod√®le**. Dans le cas du mod√®le lin√©aire, nous devons estimer les param√®tres $\beta_0,\beta_1,\ .\ .\ .\ ,\beta_p$. Autrement dit, nous voulons trouver des valeurs de ces param√®tres telles que 

$$
Y\approx\beta_0+\beta_1X_1+\beta_2X_2+\ldots+\beta_pX_p.
$$

L'approche la plus courante pour ajuster le mod√®le (2.1) est **la m√©thode des moindres carr√©s** , que nous abordons plus loin dans ce document. 

Les moindres carr√©s sont l'une des nombreuses fa√ßons possibles d'ajuster le mod√®le lin√©aire. A savoir qu'il existe d'autres approches pour estimer les param√®tres de (2.1).

<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 50%;"
    src="../images/Modele_Lineaire_Ajuste.png" 
    alt="Moore's law">
</img>

<b>FIG 2.4</b><i> ![Un mod√®le lin√©aire ajust√© par les moindres carr√©s aux donn√©es de revenu de la figure 2.3. Les observations sont repr√©sent√©es en rouge, et le plan jaune indique l'ajustement des moindrescarr√©s aux donn√©es.](https://www.statlearning.com)</i>   

L'approche bas√©e sur le mod√®le que nous venons de d√©crire est dite param√©trique ; elle r√©duit le probl√®me de l'estimation de $f$ √† celui de l'estimation d'un ensemble de param√®tres. 

Le fait de supposer une forme param√©trique pour $f$ simplifie le probl√®me de l'estimation de $f$ car il est g√©n√©ralement beaucoup plus facile d'estimer un ensemble de param√®tres, tels que $\beta_0,\beta_1,\ .\ .\ .\ ,\beta_p$ dans le mod√®le lin√©aire (2.1), que d'ajuster une fonction $f$ enti√®rement arbitraire. 

**L'inconv√©nient potentiel d'une approche param√©trique est que le mod√®le que nous choisissons ne correspondra g√©n√©ralement pas √† la v√©ritable forme inconnue de $f$**. Si le mod√®le choisi est trop √©loign√© de la v√©ritable $f$, notre estimation sera mauvaise. **Nous pouvons essayer de r√©soudre ce probl√®me en choisissant des mod√®les flexibles qui peuvent s'adapter √† de nombreuses formes fonctionnelles diff√©rentes pour $f$**. 

Mais en g√©n√©ral, **l'adaptation d'un mod√®le plus flexible n√©cessite l'estimation d'un plus grand nombre de param√®tres**. **Ces mod√®les plus complexes peuvent conduire √† un ph√©nom√®ne connu sous le nom d'ajustement excessif des donn√©es, ce qui signifie essentiellement qu'ils suivent les erreurs, ou le bruit, de trop pr√®s** (**overfitting**). 

La $figure\ 2.4$ pr√©sente un exemple de l'approche param√©trique appliqu√©e aux donn√©es de revenu de la $figure\ 2.3$. Nous avons ajust√© un mod√®le lin√©aire de la forme 

$$
income\ \approx\ \beta_0\ +\ \beta_1\ \times\ education\ +\ \beta_2\ \times\ seniority.
$$

Puisque nous avons suppos√© une relation lin√©aire entre la r√©ponse et les deux pr√©dicteurs, l'ensemble du probl√®me d'ajustement se r√©duit √† l'estimation de $\beta_0,\ \beta_1 et \beta_2$ , ce que nous faisons √† l'aide de la r√©gression lin√©aire par les moindres carr√©s. 

**En comparant la $figure\ 2.3$ √† la $figure\ 2.4$, nous pouvons constater que l'ajustement lin√©aire donn√© dans la $figure\ 2.4$ n'est pas tout √† fait correct : le v√©ritable $f$ pr√©sente une certaine courbure qui n'est pas prise en compte dans l'ajustement lin√©aire.**

<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 50%;"
    src="../images/Ajustement_spline_Modele_Lineaire.png" 
    alt="Moore's law">
</img>

<b>FIG 2.5</b><i> ![Un ajustement spline lisse √† plaque mince aux donn√©es de revenu de la figure 2.3 est repr√©sent√© en jaune ; les observations sont affich√©es en rouge.](https://www.statlearning.com/)</i>  

Toutefois, l'ajustement lin√©aire semble encore bien rendre compte de la relation positive entre les ann√©es d'√©tudes et le revenu, ainsi que de la relation l√©g√®rement moins positive entre l'anciennet√© et le revenu. Il se peut qu'avec un si petit nombre d'observations, ce soit le mieux que nous puissions faire.

<a name="2-1-2-2"/>

#### [2.1.2.2 M√©thodes non param√©triques](#2-1-2-2) ####

[Retour TOC](#toc)

**Les m√©thodes non param√©triques ne font pas d'hypoth√®ses explicites sur la forme fonctionnelle de $f$. Elles cherchent plut√¥t √† obtenir une estimation de $f$ qui se rapproche le plus possible des points de donn√©es, sans √™tre trop grossi√®re ou ondul√©e.** 

**Ces approches peuvent pr√©senter un avantage majeur par rapport aux approches param√©triques** : en √©vitant l'hypoth√®se d'une forme fonctionnelle particuli√®re pour $f$, **elles ont la possibilit√© d'ajuster avec pr√©cision un plus grand nombre de formes possibles pour $f$.** 

**Toute approche param√©trique comporte la possibilit√© que la forme fonctionnelle utilis√©e pour estimer $f$ soit tr√®s diff√©rente de la vraie fonction $f$**, auquel cas le mod√®le r√©sultant ne s'ajustera pas bien aux donn√©es. 

En revanche, les approches non param√©triques √©vitent compl√®tement ce danger, puisqu'aucune hypoth√®se sur la forme de $f$ n'est formul√©e. 
Mais **les approches non param√©triques souffrent d'un inconv√©nient majeur** : comme elles ne r√©duisent pas le probl√®me de l'estimation de $f$ √† un petit nombre de param√®tres, **il faut un tr√®s grand nombre d'observations** (bien plus que ce qui est g√©n√©ralement n√©cessaire pour une approche param√©trique) **pour obtenir une estimation pr√©cise de $f$**. 

La $figure\ 2.5$ pr√©sente un exemple d'approche non param√©trique de l'ajustement des donn√©es du revenu. Une spline √† plaque mince est utilis√©e pour estimer $f$. Cette approche n'impose pas de mod√®le pr√©-sp√©cifi√© pour $f$. Elle tente plut√¥t de produire une estimation pour f qui soit aussi proche que possible des donn√©es observ√©es, √† condition que l'ajustement - c'est-√†-dire la surface jaune de la $figure\ 2.5$ - soit lisse. 

<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 50%;"
    src="../images/Ajustement_spline_Modele_Lineaire_non_Lisse.png" 
    alt="Moore's law">
</img>

<b>FIG 2.6</b><i> ![Ajustement approximatif par spline √† plaque mince des donn√©es de revenu de la figure 2.3. Cet ajustement ne fait aucune erreur sur les donn√©es d'apprentissage.](https://www.statlearning.com/)</i>  

Dans ce cas, l'ajustement non param√©trique a permis d'obtenir une estimation remarquablement pr√©cise de la vraie $f$ illustr√©e √† la $figure\ 2.3$. Afin d'ajuster une spline √† plaque mince, l'analyste de donn√©es doit s√©lectionner un niveau de lissage. La $figure\ 2.6$ montre le m√™me ajustement spline √† plaque mince en utilisant un niveau de lissage plus faible, permettant un ajustement plus grossier. 

L'estimation qui en r√©sulte correspond parfaitement aux donn√©es observ√©es !  Cependant, l'ajustement spline illustr√© √† la $figure\ 2.6$ est beaucoup plus variable que la fonction r√©elle $f$, de la $figure\ 2.3$. **Il s'agit d'un exemple d'ajustement excessif des donn√©es, dont nous avons parl√© pr√©c√©demment.** 

Il s'agit d'une situation ind√©sirable car l'ajustement obtenu ne donnera pas d'estimations pr√©cises de la r√©ponse sur de nouvelles observations qui ne faisaient pas partie de l'ensemble de donn√©es d'apprentissage initial.

 Comme nous l'avons vu, les m√©thodes param√©triques et non param√©triques d'apprentissage statistique pr√©sentent des avantages et des inconv√©nients. 

<a name="2-1-3"/>

### [2.1.3. Le compromis entre la pr√©cision de la pr√©diction et l'interpr√©tation du mod√®le Interpr√©table](#2-1-3) ###

[Retour TOC](#toc)

Parmi les nombreuses m√©thodes que nous examinons, certaines sont moins flexibles, ou plus restrictives, dans le sens o√π elles ne peuvent produire qu'une gamme relativement restreinte de formes pour estimer $f$. Par exemple, **la r√©gression lin√©aire** **est une approche relativement peu flexible**, car elle ne peut g√©n√©rer que des fonctions lin√©aires telles que les lignes illustr√©es √† la $figure\ 2.1$ ou le plan illustr√© √† la $figure\ 2.4.$  D'autres m√©thodes, telles que les splines √† plaques minces illustr√©es aux $figures\ 2.5\ et\ 2.6$, sont beaucoup plus souples car elles peuvent g√©n√©rer un √©ventail beaucoup plus large de formes possibles pour estimer $f$. 

<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 70%;"
    src="../images/Flexibility_Inter.png" 
    alt="Flexibility_Inter">
</img>

<b>FIG 2.7</b><i> ![Une repr√©sentation du compromis entre la flexibilit√© et l'interpr√©tabilit√©, en utilisant diff√©rentes m√©thodes d'apprentissage statistique. En g√©n√©ral, plus la flexibilit√© d'une m√©thode augmente, plus son interpr√©tabilit√© diminue.](https://www.statlearning.com)</i>

On peut raisonnablement se poser la question suivante : **pourquoi choisir d'utiliser une m√©thode plus restrictive plut√¥t qu'une approche tr√®s souple ?**  Il existe plusieurs raisons pour lesquelles nous pourrions pr√©f√©rer un mod√®le plus restrictif.  Si nous sommes principalement int√©ress√©s par l'inf√©rence, les mod√®les restrictifs sont beaucoup plus faciles √† interpr√©ter. Par exemple, lorsque l'inf√©rence est l'objectif, le mod√®le lin√©aire peut √™tre un bon choix car il sera assez facile de comprendre la relation entre $Y$ et $X_1,X_2\ ,\ .\ .\ .\ ,X_p$. 

En revanche, les approches tr√®s flexibles, telles que les splines pr√©sent√©es aux $figures\ 2.5\ et\ 2.6$ ainsi que les m√©thodes de boosting, peuvent conduire √† des estimations de $f$ si compliqu√©es qu'il est difficile de comprendre comment chaque pr√©dicteur individuel est associ√© √† la r√©ponse.  

***Remarques:***  En math√©matiques appliqu√©es et en analyse num√©rique, [[13](https://fr.wikipedia.org/wiki/Spline)] **une spline** est une fonction d√©finie par morceaux par des polyn√¥mes. Dans les probl√®mes d'interpolation, la m√©thode des splines est tr√®s souvent pr√©f√©r√©e √† l'interpolation polynomiale. Les splines sont √©galement utilis√©es dans les probl√®mes de lissage de donn√©es exp√©rimentales ou de statistiques. Les splines sont utilis√©es pour repr√©senter num√©riquement des contours complexes. Leur mise en ≈ìuvre est simple. [[14](https://fr.wikipedia.org/wiki/Boosting,"*Boosting)] **Le boosting** est un domaine de l'apprentissage automatique. C'est un principe qui regroupe de nombreux algorithmes qui s'appuient sur des ensembles de classifieurs binaires : le boosting optimise leurs performances. 

La $figure\ 2.7$ illustre le compromis entre flexibilit√© et interpr√©tabilit√© pour certaines m√©thodes.

La **r√©gression lin√©aire par les moindres carr√©s est relativement peu flexible mais tout √† fait interpr√©table.** 

**Le lasso** s'appuie sur le mod√®le lin√©aire (2.4) mais utilise une proc√©dure d'ajustement alternative pour estimer les coefficients $\beta_0,\beta_1,\ .\ .\ .\ ,\beta_p$. La nouvelle proc√©dure est plus restrictive dans l'estimation des coefficients, et fixe un certain nombre d'entre eux √† exactement z√©ro. 

Ainsi, dans ce sens, **le lasso est une approche moins flexible que la r√©gression lin√©aire**.  Elle est √©galement plus facile √† interpr√©ter que la r√©gression lin√©aire, car dans le mod√®le final, la variable de r√©ponse ne sera li√©e qu'√† un petit sous-ensemble de pr√©dicteurs, √† savoir ceux dont les coefficients sont estim√©s non nuls. 

**Les mod√®les additifs g√©n√©ralis√©s** (**MAG**) √©tendent plut√¥t le mod√®le lin√©aire (2.4) pour permettre certaines relations non lin√©aires. Par cons√©quent, **les MAG sont plus flexibles que la r√©gression lin√©aire**. Ils sont √©galement **un peu moins interpr√©tables que la r√©gression lin√©aire**, car la relation entre chaque pr√©dicteur et la r√©ponse est maintenant mod√©lis√©e par une courbe. 

Enfin, **les m√©thodes enti√®rement non lin√©aires telles que le bagging, le boosting, les machines √† vecteurs de support avec des noyaux non lin√©aires et les r√©seaux neuronaux (apprentissage profond)  sont des approches tr√®s flexibles mais plus difficiles √† interpr√©ter.** 

Nous avons √©tabli que lorsque l'inf√©rence est l'objectif, il y a des avantages √©vidents √† utiliser des m√©thodes d'apprentissage statistique simples et relativement peu flexibles.  

Dans certains cas, cependant, nous ne sommes int√©ress√©s que par la pr√©diction, et l'interpr√©tabilit√© du mod√®le pr√©dictif n'est tout simplement pas importante. Par exemple, si nous cherchons √† d√©velopper un algorithme pour pr√©dire le prix d'une action, notre seule exigence pour l'algorithme est qu'il pr√©dise avec pr√©cision - l'interpr√©tabilit√© n'est pas une pr√©occupation. Dans ce contexte, on pourrait s'attendre √† ce qu'il soit pr√©f√©rable d'utiliser le mod√®le le plus flexible disponible. 

**√âtonnamment, ce n'est pas toujours le cas ! Nous obtiendrons souvent des pr√©dictions plus pr√©cises en utilisant une m√©thode moins flexible. Ce ph√©nom√®ne, qui peut sembler contre-intuitif √† premi√®re vue, est li√© au potentiel d'overfitting des m√©thodes tr√®s flexibles.** Nous avons vu un exemple d'overfitting √† la $figure\ 2.6$. 

<a name="2-1-4"/>

### [2.1.4 Apprentissage supervis√© et apprentissage non supervis√©](#2-1-4) ###

[Retour TOC](#toc)

La plupart des probl√®mes d'apprentissage statistique entrent dans l'une des deux cat√©gories suivantes : **supervis√© ou non supervis√©**. Les exemples que nous avons abord√©s jusqu'√† pr√©sent dans cette section rel√®vent tous du domaine de l'apprentissage supervis√©. Pour chaque observation des mesures du pr√©dicteur $x_i$, $i=1,\ .\ .\ .\ n$ , il existe une mesure de r√©ponse associ√©e ${y}_{i}$. 

Nous souhaitons ajuster un mod√®le qui relie la r√©ponse aux pr√©dicteurs, dans le but de pr√©dire avec pr√©cision la r√©ponse pour les observations futures (pr√©diction) ou de mieux comprendre la relation entre la r√©ponse et les pr√©dicteurs (inf√©rence). 

De nombreuses m√©thodes classiques d'apprentissage statistique, telles que la r√©gression lin√©aire et la r√©gression logistique, ainsi que des approches plus modernes telles que les $MAG$ , le $boosting$ et les $machines\ √†\ vecteurs\ de\ support$, fonctionnent dans le domaine de l'apprentissage supervis√©.  

En revanche, l'apprentissage non supervis√© d√©crit la situation un peu plus difficile dans laquelle pour chaque observation ${i}={1},\ .\ .\ .\ ,{n}$, nous observons un vecteur de mesures $x_i$ mais pas de r√©ponse associ√©e $y_i$. 

Il n'est pas possible d'ajuster un mod√®le de r√©gression lin√©aire, puisqu'il n'y a pas de variable de r√©ponse √† pr√©dire. Dans ce contexte, nous travaillons en quelque sorte √† l'aveugle ; la situation est qualifi√©e de non supervis√©e parce qu'il nous manque une variable de r√©ponse qui puisse superviser notre analyse. 

**Quel type d'analyse statistique est possible ?** 
**Nous pouvons chercher √† comprendre les relations entre les variables ou entre les observations**. Un outil d'apprentissage statistique que nous pouvons utiliser dans ce contexte est l'analyse en grappes, ou clustering. L'objectif de l'analyse en clustering est de d√©terminer, sur la base de $x_1,...,x_n$, si les observations appartiennent √† des groupes relativement distincts. Par exemple, dans une √©tude de segmentation de march√©, nous pouvons observer de multiples caract√©ristiques (variables) de clients potentiels, telles que le code postal, le revenu familial et les habitudes d'achat. Nous pouvons penser que les clients appartiennent √† des groupes diff√©rents, tels que les gros d√©pensiers et les petits d√©pensiers. Si les informations sur les habitudes de consommation de chaque client √©taient disponibles, une analyse supervis√©e serait alors possible. Cependant, ces informations ne sont pas disponibles, c'est-√†-dire que nous ne savons pas si chaque client potentiel est un gros d√©pensier ou non. Dans ce cas, nous pouvons essayer de regrouper les clients sur la base des variables mesur√©es, afin d'identifier des groupes distincts de clients potentiels. L'identification de ces groupes peut s'av√©rer int√©ressante car il se peut que les groupes diff√®rent en ce qui concerne certaines propri√©t√©s int√©ressantes, comme les habitudes de consommation. 

La $figure\ 2.8$ fournit une illustration simple du probl√®me de clustering. 

<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 70%;"
    src="../images/Clustering_3_groupes.png" 
    alt="Clustering_3_groupes">
</img>

<b>FIG 2.8</b><i> ![Un ensemble de donn√©es de clustering impliquant trois groupes. Chaque groupe est repr√©sent√© par un symbole de couleur diff√©rente. **√Ä gauche** : les trois groupes sont bien s√©par√©s. Dans ce contexte, une approche de clustering devrait r√©ussir √† identifier les trois groupes. **A droite** : Il y a un certain chevauchement entre les groupes. Maintenant, la t√¢che de clustering est plus difficile.](https://www.statlearning.com/)</i>

Nous avons repr√©sent√© 150 observations avec des mesures sur deux variables, $X_1$ et $X_2$. Chaque observation correspond √† l'un des trois groupes distincts. A des fins d'illustration, nous avons repr√©sent√© les membres de chaque groupe par des couleurs et des symboles diff√©rents. Cependant, dans la pratique, les appartenances aux groupes sont inconnues, et l'objectif est de d√©terminer le groupe auquel appartient chaque observation. 

Dans le panneau de gauche de la $figure\ 2.8$, cette t√¢che est relativement facile car les groupes sont bien s√©par√©s. En revanche, le panneau de droite illustre une situation plus difficile dans laquelle il y a un certain chevauchement entre les groupes. On ne peut s'attendre √† ce qu'une m√©thode de clustering affecte tous les points qui se chevauchent au bon groupe (bleu, vert ou orange).  

Dans les exemples pr√©sent√©s √† la $figure\ 2.8$, il n'y a que deux variables, et on peut donc simplement inspecter visuellement les nuages de points des observations afin d'identifier les groupes. Cependant, dans la pratique, nous rencontrons souvent des ensembles de donn√©es qui contiennent beaucoup plus de deux variables. Dans ce cas, nous ne pouvons pas facilement tracer les observations. Par exemple, s'il y a $p$ variables dans notre ensemble de donn√©es, alors $p(p-1)/2$ diagrammes de dispersion distincts peuvent √™tre r√©alis√©s, et l'inspection visuelle n'est tout simplement pas un moyen viable d'identifier les clusters. 

**C'est pourquoi les m√©thodes de clustering automatis√©es sont importantes.** 

De nombreux probl√®mes tombent naturellement dans le paradigme de l'apprentissage supervis√© ou non supervis√©. Cependant, la question de savoir si une analyse doit √™tre consid√©r√©e comme supervis√©e ou non supervis√©e est parfois moins √©vidente. Par exemple, supposons que nous ayons un ensemble de $n$ observations et pour $m$ des observations, o√π $m < n$, nous avons √† la fois les mesures du pr√©dicteur et une mesure de la r√©ponse et pour les $n{-}m$ observations restantes, nous avons des mesures du pr√©dicteur mais pas de mesure de la r√©ponse. 

Un tel sc√©nario peut se produire si les pr√©dicteurs peuvent √™tre mesur√©s √† un co√ªt relativement faible mais que les r√©ponses correspondantes sont beaucoup plus co√ªteuses √† collecter. Nous appelons cette situation un probl√®me d'apprentissage semi-supervis√©. Dans ce contexte, nous souhaitons utiliser une m√©thode d'apprentissage statistique qui peut incorporer les $m$ observations pour lesquelles des mesures de r√©ponse sont disponibles ainsi que les $n{-}m$ observations pour lesquelles elles ne le sont pas. 

<a name="2-1-5"/>

### [2.1.5  Probl√®mes de r√©gression et de classification](#2-1-5) ###

[Retour TOC](#toc)

Les variables peuvent √™tre caract√©ris√©es comme √©tant quantitatives ou qualitatives (√©galement appel√©es cat√©goriques). Les variables quantitatives prennent des valeurs num√©riques, par exemple l'√¢ge, la taille ou le revenu d'une personne, la valeur d'une maison ou le prix d'une action. 

En revanche, les variables qualitatives prennent des valeurs dans l'une des $K{-}classes$ ou cat√©gories diff√©rentes. Parmi les exemples de variables qualitatives, citons l'√©tat civil d'une personne (mari√©e ou non), la marque d'un produit achet√© ( marque $A$, $B$ ou $C$ ), le fait qu'une personne ne rembourse pas une dette (oui ou non) ou le diagnostic d'un cancer (leuc√©mie my√©log√®ne aigu√´, leuc√©mie lymphoblastique aigu√´ ou pas de leuc√©mie). 

**Nous avons tendance √† d√©signer les probl√®mes comportant une r√©ponse quantitative comme des probl√®mes de r√©gression, tandis que ceux impliquant une r√©ponse qualitative sont souvent appel√©s des probl√®mes de classification.** Toutefois, la distinction n'est pas toujours aussi nette. 

**La r√©gression lin√©aire par les moindres carr√©s est utilis√©e avec une r√©ponse quantitative**, tandis que **la r√©gression logistique est g√©n√©ralement utilis√©e avec une r√©ponse qualitative** (√† deux classes ou binaire). Ainsi, malgr√© son nom, **la r√©gression logistique est une m√©thode de classification**. **Mais comme elle estime les probabilit√©s de classe, elle peut √©galement √™tre consid√©r√©e comme une m√©thode de r√©gression**. 

Certaines m√©thodes statistiques, telles que les ${K}{-}nearestneighbors$  et le $boosting$, peuvent √™tre utilis√©es dans le cas de r√©ponses quantitatives ou qualitatives.  

Nous avons tendance √† s√©lectionner les m√©thodes d'apprentissage statistique en fonction du caract√®re quantitatif ou qualitatif de la r√©ponse, c'est-√†-dire que nous pouvons utiliser la r√©gression lin√©aire dans le cas de r√©ponses quantitatives et la r√©gression logistique dans le cas de r√©ponses qualitatives. 

Cependant, le fait que les pr√©dicteurs soient qualitatifs ou quantitatifs est g√©n√©ralement consid√©r√© comme moins important. La plupart des m√©thodes d'apprentissage statistique peuvent √™tre appliqu√©es quel que soit le type de variable pr√©dictive, √† condition que les pr√©dicteurs qualitatifs soient correctement cod√©s avant la r√©alisation de l'analyse.

<a name="2-2"/>

## [2.2 √âvaluation de la pr√©cision du mod√®le](#2-2) ##

[Retour TOC](#toc)

**Pourquoi est-il n√©cessaire de pr√©senter autant d'approches d'apprentissage statistique diff√©rentes, plut√¥t que de se contenter d'une seule m√©thode optimale ?** 
Aucune m√©thode ne domine toutes les autres sur tous les ensembles de donn√©es possibles. Sur un ensemble de donn√©es particulier, une m√©thode sp√©cifique peut √™tre la plus efficace, mais une autre m√©thode peut √™tre plus efficace sur un ensemble de donn√©es similaire mais diff√©rent. 

Il est donc important de d√©cider, pour un ensemble de donn√©es donn√©, quelle m√©thode produit les meilleurs r√©sultats. **Le choix de la meilleure approche peut √™tre l'un des aspects les plus difficiles de l'apprentissage statistique dans la pratique.**  

Dans cette section, nous abordons certains des concepts les plus importants qui interviennent dans la s√©lection d'une proc√©dure d'apprentissage statistique pour un ensemble de donn√©es sp√©cifique. 

<a name="2-2-1"/>

### [2.2.1.  Mesurer la qualit√© de l'ajustement](#2-2-1) ###

[Retour TOC](#toc)

Afin d'√©valuer la performance d'une m√©thode d'apprentissage statistique sur un ensemble de donn√©es donn√©, il faut pouvoir mesurer dans quelle mesure ses pr√©dictions correspondent aux donn√©es observ√©es. Autrement dit, nous devons quantifier la mesure dans laquelle la valeur de r√©ponse pr√©dite pour une observation donn√©e est proche de la valeur de r√©ponse r√©elle pour cette observation. 

Dans le cadre de la r√©gression, la mesure la plus couramment utilis√©e est **l'erreur quadratique moyenne** (**EQM**), donn√©e par 


$$
EQM = \frac{1}{n}\sum_{i=n}^n(y_i - \hat{f} (x_i))^2, \hspace{6em} (2.5)
$$


o√π  $\hat{f} (x_i)$ est la pr√©diction que $\hat{f}$ donne pour la $i^{√®me}$ observation. L'**EQM** sera faible si les r√©ponses pr√©dites sont tr√®s proches des r√©ponses r√©elles, et sera grande si pour certaines des observations, les r√©ponses pr√©dites et r√©elles diff√®rent consid√©rablement.  L'**EQM** dans (2.5) est calcul√©e √† l'aide des donn√©es d'apprentissage qui ont √©t√© utilis√©es pour ajuster le mod√®le, et devrait donc √™tre appel√©e plus pr√©cis√©ment l'**EQM** d'apprentissage. 

Mais en g√©n√©ral, nous ne nous soucions pas vraiment de l'efficacit√© de la m√©thode sur les donn√©es d'apprentissage. Nous nous int√©ressons plut√¥t √† la pr√©cision des pr√©dictions que nous obtenons lorsque nous appliquons notre m√©thode √† des donn√©es de test in√©dites. 

**Pourquoi cela nous int√©resse-t-il ?** 
Supposons que nous soyons int√©ress√©s par le d√©veloppement d'un algorithme permettant de pr√©dire le prix d'une action en fonction des rendements boursiers pr√©c√©dents. Nous pouvons entra√Æner la m√©thode en utilisant les rendements boursiers des six derniers mois. Mais la capacit√© de notre m√©thode √† pr√©dire le prix de l'action de la semaine derni√®re ne nous int√©resse pas vraiment. Nous nous int√©ressons plut√¥t √† sa capacit√© √† pr√©dire le prix de demain ou du mois prochain. 

Dans le m√™me ordre d'id√©es, supposons que nous disposions de mesures cliniques (poids, pression art√©rielle, taille, √¢ge, ant√©c√©dents familiaux de maladie) pour un certain nombre de patients, ainsi que des observations indiquant si chaque patient est diab√©tique. Nous pouvons utiliser ces patients pour former une m√©thode d'apprentissage statistique permettant de pr√©dire le risque de diab√®te sur la base des mesures cliniques. 
En pratique, nous voulons que cette m√©thode pr√©dise avec pr√©cision le risque de diab√®te pour les futurs patients sur la base de leurs mesures cliniques. Nous ne sommes pas tr√®s int√©ress√©s par le fait que la m√©thode pr√©dise avec pr√©cision ou non le risque de diab√®te pour les patients utilis√©s pour former le mod√®le, puisque nous savons d√©j√† lesquels de ces patients sont diab√©tiques.  

Pour exprimer cela de mani√®re plus math√©matique, supposons que nous ajustons notre m√©thode d'apprentissage statistique sur nos observations d‚Äôapprentissage ${(x_1,\ y_1),\ (x_2,\ y_2),...,\ (x_n,\ y_n)}$, et nous obtenons l‚Äôestimation $\hat f$. Nous pouvons alors calculer $\hat f(x_1),\hat f(x_2), . . . , \hat f(x_n)$.  Si ces valeurs sont approximativement √©gales √† $y_1, y_2, . . . , y_n$, alors le **EQM** d‚Äôapprentissage donn√© par (2.5) est petit. 

Cependant, nous ne sommes pas vraiment int√©ress√©s par le fait de savoir si $\hat f(x_i) \approx y_i$ ; au lieu de cela, nous voulons savoir si $\hat f(x_0)$ est approximativement √©gal √† $y_0$, o√π $(x_0, y_0)$ est une observation test non vue pr√©c√©demment et non utilis√©e pour entra√Æner **la m√©thode d'apprentissage statistique**. **Nous voulons choisir la m√©thode qui donne le EQM de test le plus bas, par opposition au EQM d'apprentissage le plus bas.** 

En d'autres termes, si nous avions un grand nombre d'observations de test, nous pourrions calculer 


$$
Ave(y_0 - \hat{f} (x_0))^2
$$




**l'erreur quadratique moyenne de pr√©diction** pour ces observations de test $(x_0, y_0)$. Nous aimerions s√©lectionner le mod√®le pour lequel cette quantit√© est la plus petite possible.  

**Comment pouvons-nous essayer de s√©lectionner une m√©thode qui minimise l'EQM de test ?** 
Dans certains cas, nous pouvons disposer d'un ensemble de donn√©es de test, c'est-√†-dire que nous pouvons avoir acc√®s √† un ensemble d'observations qui n'ont pas √©t√© utilis√©es pour entra√Æner la m√©thode d'apprentissage statistique. Nous pouvons alors simplement √©valuer (2.6) sur les observations de test, et s√©lectionner la m√©thode d'apprentissage pour laquelle l'**EQM** de test est la plus petite. 

**Mais que se passe-t-il si aucune observation de test n'est disponible ?** 
Dans ce cas, on pourrait imaginer de s√©lectionner simplement une m√©thode d'apprentissage statistique qui minimise l'**EQM** d‚Äôapprentissage (2.5). Cela semble √™tre une approche judicieuse, puisque l'**EQM** d'apprentissage et l'**EQM** de test semblent √™tre √©troitement li√©es.



<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 60%;"
    src="../images/RL_Ajsutement_Lissage.png" 
    alt="RL_Ajsutement_Lissage">
</img>

<b>FIG 2.9</b><i> ![**Gauche** : Donn√©es simul√©es √† partir de f, indiqu√©es en noir. Trois estimations de f sont pr√©sent√©es : la ligne de r√©gression lin√©aire (courbe orange) et deux ajustements spline de lissage (courbes bleue et verte). **A droite** : EQM d'apprentissage (courbe grise), EQM de test (courbe rouge), et EQM de test minimum possible pour toutes les m√©thodes (ligne pointill√©e). Les carr√©s repr√©sentent les EQM d'apprentissage et de test pour les trois ajustements pr√©sent√©s dans le panneau de gauche.](https://www.statlearning.com/)</i>

Malheureusement, cette strat√©gie pose un probl√®me fondamental, rien ne garantit que la m√©thode pr√©sentant l'**EQM** d'apprentissage la plus faible aura √©galement l'**EQM** de test la plus faible. En gros, le probl√®me est que de nombreuses m√©thodes statistiques estiment sp√©cifiquement les coefficients de mani√®re √† minimiser l'**EQM** de l'ensemble d'apprentissage. Pour ces m√©thodes, l'**EQM** de l'ensemble d'apprentissage peut √™tre assez faible, mais l'**EQM** du test est souvent beaucoup plus importante.  

La $figure\ 2.9$ illustre ce ph√©nom√®ne sur un exemple simple. Dans le panneau de gauche de la $figure\ 2.9$, nous avons g√©n√©r√© des observations √† partir de (2.1) avec le vrai $f$ donn√© par la courbe noire. Les courbes orange, bleue et verte illustrent trois estimations possibles de $f$ obtenues √† l'aide de m√©thodes pr√©sentant des niveaux de flexibilit√© croissants. 

- La ligne orange repr√©sente l'ajustement par r√©gression lin√©aire, qui est relativement peu flexible. 
- Les courbes bleue et verte ont √©t√© produites √† l'aide de splines de lissage avec diff√©rents niveaux de lissage. Il est clair que plus le niveau de flexibilit√© augmente, plus les courbes s'ajustent aux donn√©es observ√©es. La courbe verte est la plus flexible et s'adapte tr√®s bien aux donn√©es ; cependant, nous observons qu'elle s'adapte mal au vrai $f$ (repr√©sent√© en noir) car elle est trop ondul√©e. En ajustant le niveau de flexibilit√© de l'ajustement par spline de lissage, nous pouvons produire de nombreux ajustements diff√©rents pour ces donn√©es.  

Nous passons maintenant au panneau de droite de la $figure\ 2.9$. La courbe grise affiche l'**EQM** moyenne de l'apprentissage en fonction de la flexibilit√© ou plus formellement des degr√©s de libert√© pour un certain nombre de splines de lissage. **Les degr√©s de libert√© sont une quantit√© qui r√©sume la flexibilit√© d'une courbe**.

Les carr√©s orange, bleus et verts indiquent les **EQM** associ√©es aux courbes correspondantes dans le panneau de gauche. Une courbe plus restreinte et donc plus lisse poss√®de moins de degr√©s de libert√© qu'une courbe ondul√©e - notez que dans la $figure\ 2.9$, la r√©gression lin√©aire se situe √† l'extr√©mit√© la plus restrictive, avec deux degr√©s de libert√©. 

**L'EQM d'apprentissage diminue de fa√ßon monotone √† mesure que la flexibilit√© augmente.** 

Dans cet exemple, le v√©ritable $f$ n'est pas lin√©aire, et l'ajustement lin√©aire orange n'est donc pas assez flexible pour estimer $f$ correctement. 

La courbe verte pr√©sente l'**EQM** d'apprentissage la plus faible des trois m√©thodes, car elle correspond √† la plus flexible des trois courbes ajust√©es dans le panneau de gauche. 

Dans cet exemple, nous connaissons la vraie fonction $f$, et nous pouvons donc √©galement calculer le **EQM** de test sur un tr√®s grand ensemble de test, en fonction de la flexibilit√© (le **EQM** de test est repr√©sent√© par la courbe rouge dans le panneau de droite de la $figure\ 2.9$). Comme pour l'**EQM** d'entra√Ænement, l'**EQM** de test diminue initialement √† mesure que le niveau de flexibilit√© augmente. Cependant, √† un moment donn√©, le **EQM** de test se stabilise, puis recommence √† augmenter. Par cons√©quent, 

- les courbes orange et verte ont toutes deux un **EQM** de test √©lev√©. 
- La courbe bleue minimise l'**EQM** de test, ce qui n'est pas surprenant √©tant donn√© que visuellement, elle semble estimer $f$ le mieux dans le panneau de gauche de la $figure 2.9$. 
- La ligne pointill√©e horizontale indique $Var( \varepsilon )$, l'erreur irr√©ductible dans (2.3), qui correspond √† la plus faible **EQM** de test r√©alisable parmi toutes les m√©thodes possibles. 
- Par cons√©quent, la spline de lissage repr√©sent√©e par la courbe bleue est proche de l'optimum.  

Dans le panneau de droite de la $figure\ 2.9$, √† mesure que la flexibilit√© de la m√©thode d'apprentissage statistique augmente, nous observons une diminution monotone de la **EQM** d'apprentissage et une forme en $\bigcup$ de la **EQM** de test. Il s'agit d'une propri√©t√© fondamentale de l'apprentissage statistique qui est valable quel que soit l'ensemble de donn√©es en question et quelle que soit la m√©thode statistique utilis√©e. **Plus la flexibilit√© du mod√®le augmente, plus l'EQM d'apprentissage diminue, mais pas n√©cessairement l'EQM de test.** 

**Lorsqu'une m√©thode donn√©e produit une petite EQM d'apprentissage mais une grande EQM de test, on dit que nous surestimons(overfitting) les donn√©es**. Cela se produit parce que notre proc√©dure d'apprentissage statistique s'efforce trop de trouver des mod√®les dans les donn√©es d'apprentissage, et peut d√©tecter certains mod√®les qui sont juste dus au hasard plut√¥t qu'√† de v√©ritables propri√©t√©s de la fonction inconnue $f$. 

Lorsque nous surestimons les donn√©es d'apprentissage, la **EQM** de test sera tr√®s √©lev√©e parce que les mod√®les suppos√©s que la m√©thode a trouv√©s dans les donn√©es d'apprentissage n'existent tout simplement pas dans les donn√©es de test. Notez qu'ind√©pendamment de l'existence ou non d'une surestimation (overfitting), nous nous attendons presque toujours √† ce que l'**EQM** d'apprentissage soit plus petite que l'**EQM** de test, car la plupart des m√©thodes d'apprentissage statistique cherchent directement ou indirectement √† minimiser l'**EQM** d'apprentissage. **L'overfitting se r√©f√®re sp√©cifiquement au cas o√π un mod√®le moins flexible aurait donn√© un EQM de test plus petit.**

La $figure\ 2.10$ pr√©sente un autre exemple dans lequel le vrai $f$ est approximativement lin√©aire. Nous observons √† nouveau que l'**EQM** de formation diminue de fa√ßon monotone √† mesure que la flexibilit√© du mod√®le augmente, et que l'**EQM** de test a une forme en U. Cependant, comme la v√©rit√© est proche de la lin√©arit√©, l'**EQM** de test ne diminue que l√©g√®rement avant d'augmenter √† nouveau, de sorte que l'ajustement orange des moindres carr√©s est nettement meilleur que la courbe verte hautement flexible. 
Enfin, la $figure\ 2.11$ pr√©sente un exemple dans lequel $f$ est fortement non lin√©aire. Les courbes **EQM** d'apprentissage et de test pr√©sentent toujours les m√™mes sch√©mas g√©n√©raux, mais il y a maintenant une diminution rapide dans les deux courbes avant que la **EQM** de test ne commence √† augmenter lentement.



<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 60%;"
    src="../images/Detail_fig_29.png" 
    alt="Detail_fig_29">
</img>

<b>FIG 2.10</b><i> ![Les d√©tails sont les m√™mes que ceux de la figure 2.9, avec un f r√©el diff√©rent qui est beaucoup plus proche de la lin√©arit√©. Dans ce contexte, la r√©gression lin√©aire fournit un tr√®s bon ajustement aux donn√©es.](https://www.statlearning.com/)</i>



Dans la pratique, on peut g√©n√©ralement calculer l'**EQM** d'apprentissage avec une relative facilit√©, mais l'estimation de l'**EQM** de test est beaucoup plus difficile car on ne dispose g√©n√©ralement pas de donn√©es de test.  

Comme l'illustrent les trois exemples pr√©c√©dents, le niveau de flexibilit√© correspondant au mod√®le pr√©sentant l'**EQM** de test minimale peut varier consid√©rablement selon les ensembles de donn√©es.  Une m√©thode importante est la validation crois√©e qui est une m√©thode d'estimation de l'**EQM** de test √† l'aide des donn√©es d'apprentissages.

<a name="2-3"/>

## [2.3. Le compromis biais-variance](#2-3) ##

[Retour TOC](#toc)

La forme en $\bigcup$ observ√©e dans les courbes d'**EQM** de test ( $figures\ 2.9-2.11$ ) s'av√®re √™tre le r√©sultat de deux propri√©t√©s concurrentes des m√©thodes d'apprentissage statistique.  **Il est possible de montrer que le EQM de test attendu, pour une valeur $x_0$ donn√©e, peut toujours √™tre d√©compos√© en la somme de trois quantit√©s fondamentales : la variance de $\hat{f}(x_0)$, le biais au carr√© de $\hat{f}(x0)$ et la variance des termes d'erreur $\varepsilon$**. C'est-√†-dire ,


$$
E(y_0 - \hat{f}(x_0))^2=Var( \hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2+Var( \varepsilon). \hspace{6 em}(2.7)
$$




Ici, la notation $E(y_0 - \hat{f}(x_0))^2$,  d√©finit la **EQM** de test attendue en $x_0$, et se r√©f√®re √† la **EQM** de test moyenne que nous obtiendrions si nous estimions $f $ de mani√®re r√©p√©t√©e en utilisant un grand nombre d'ensembles d'apprentissage, et en testant chacun d'eux √† $x_0$. 



<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 60%;"
    src="../images/Detail_fig_29_f_different.png" 
    alt="Detail_fig_29_f_different">
</img>

<b>FIG 2.11</b><i> ![Les d√©tails sont les m√™mes que ceux de la figure 2.9, avec un f diff√©rent qui est loin d'√™tre lin√©aire. Dans ce contexte, la r√©gression lin√©aire fournit un tr√®s mauvais ajustement aux donn√©es.](https://www.statlearning.com)</i>

La **EQM** globale de test attendue peut √™tre calcul√©e en faisant la moyenne de $E(y_0 - \hat{f}(x_0))^2$ sur toutes les valeurs possibles de $x_0$ dans l'ensemble de test.  L'√©quation (2.7) nous indique que pour minimiser l'erreur de test attendue, nous devons choisir une m√©thode d'apprentissage statistique qui pr√©sente simultan√©ment une faible variance et un faible biais. 

Notez que la variance est par nature une quantit√© non n√©gative, et que le biais au carr√© est √©galement non n√©gatif. Par cons√©quent, nous voyons que l'**EQM** de test attendue ne peut jamais √™tre inf√©rieure √† $Var( \epsilon )$, l'erreur irr√©ductible de (2.3).  

**Qu'entendons-nous par variance et biais d'une m√©thode d'apprentissage statistique ?** 
**La variance fait r√©f√©rence √† la proportion de changement de $\hat{f}$ si nous l'estimions en utilisant un ensemble de donn√©es d'apprentissage diff√©rent.** Puisque les donn√©es d‚Äôapprentissages sont utilis√©es pour ajuster la m√©thode d‚Äôapprentissage statistique, des ensembles de donn√©es d‚Äôapprentissages diff√©rents donneront lieu √† un $\hat{f}$ diff√©rent. 

Cependant, **si une m√©thode a une variance √©lev√©e, de petits changements dans les donn√©es de formation peuvent entra√Æner de grands changements dans $\hat{f}$.** **En g√©n√©ral, les m√©thodes statistiques plus flexibles ont une variance plus √©lev√©e.** 

Consid√©rons les courbes verte et orange de la $figure\ 2.9$. La courbe verte flexible suit les observations de tr√®s pr√®s. Elle pr√©sente une variance √©lev√©e car la modification de n'importe lequel de ces points de donn√©es peut entra√Æner un changement consid√©rable de l'estimation  $\hat{f}$.  En revanche, la ligne orange des moindres carr√©s est relativement inflexible et pr√©sente une faible variance, car le d√©placement d'une seule observation ne provoquera probablement qu'un faible d√©calage de la position de la ligne.  

D'autre part, **le biais d√©signe l'erreur introduite par l'approximation d'un probl√®me r√©el, qui peut √™tre extr√™mement compliqu√©, par un mod√®le beaucoup plus simple.** Par exemple, la r√©gression lin√©aire suppose qu'il existe une relation lin√©aire entre $Y$ et $X_1,X_2,\ .\ .\ .\ ,X_p$. Il est peu probable qu'un probl√®me de la vie r√©elle pr√©sente une relation lin√©aire aussi simple, et la r√©gression lin√©aire entra√Ænera donc indubitablement un biais dans l'estimation de $f$. 

Dans la $figure\ 2.11$, la vraie $f$ est essentiellement non lin√©aire, et quel que soit le nombre d'observations d'entra√Ænement qui nous sont fournies, il ne sera pas possible de produire une estimation pr√©cise √† l'aide de la r√©gression lin√©aire. En d'autres termes, la r√©gression lin√©aire entra√Æne un biais √©lev√© dans cet exemple.

Cependant, dans la $figure\ 2.10$, la v√©ritable $f$ est tr√®s proche de la lin√©arit√©, et donc, avec suffisamment de donn√©es, la r√©gression lin√©aire devrait pouvoir produire une estimation pr√©cise. 

En g√©n√©ral, les m√©thodes plus souples entra√Ænent moins de biais.  En r√®gle g√©n√©rale, √† mesure que nous utilisons des m√©thodes plus souples, la variance augmente et le biais diminue. Le taux de variation relatif de ces deux quantit√©s d√©termine si l'**EQM** du test augmente ou diminue. Lorsque nous augmentons la flexibilit√© d'une classe de m√©thodes, le biais a tendance √† diminuer initialement plus rapidement que la variance n'augmente. Par cons√©quent, l'**EQM** de test attendue diminue. 

Cependant, √† un certain point, l'augmentation de la flexibilit√© a peu d'impact sur le biais mais commence √† augmenter significativement la variance. Dans ce cas, le test **EQM** augmente. 

Notez que nous avons observ√© ce mod√®le de **EQM** de test d√©croissante suivie d'un **EQM** de test croissante dans les panneaux de droite des $figures\ 2.9-2.11$.  

Les trois graphiques de la $figure\ 2.12$ illustrent l'√©quation (2.7) pour les exemples des $figures\ 2.9-2.11$. Dans chaque cas, 

- la courbe pleine bleue repr√©sente le biais au carr√©, pour diff√©rents niveaux de flexibilit√©, tandis 
- que la courbe orange correspond √† la variance. 
- La ligne horizontale en pointill√©s repr√©sente $Var( \varepsilon )$, l'erreur irr√©ductible. 
- Enfin, la courbe rouge, correspondant au **EQM** de l'ensemble de test, est la somme de ces trois quantit√©s.

Dans les trois cas, la variance augmente et le biais diminue lorsque la flexibilit√© de la m√©thode augmente. 

Toutefois, le niveau de flexibilit√© correspondant √† l'**EQM** de test optimale diff√®re consid√©rablement entre les trois ensembles de donn√©es, car le biais au carr√© et la variance √©voluent √† des rythmes diff√©rents dans chacun des ensembles de donn√©es. 

Dans le panneau de gauche de la $figure\ 2.12$, le biais diminue rapidement au d√©part, ce qui entra√Æne une forte diminution initiale de l'**EQM** de test pr√©vue. 

En revanche, dans le panneau central de la $figure\ 2.12$, le vrai $f$ est proche de la lin√©arit√©, de sorte qu'il n'y a qu'une faible diminution du biais lorsque la flexibilit√© augmente, et l'**EQM** de test ne diminue que l√©g√®rement avant d'augmenter rapidement lorsque la variance augmente. 

Enfin, dans le panneau de droite de la $figure\ 2.12$, on observe une baisse spectaculaire du biais √† mesure que la flexibilit√© augmente, car le $f$ r√©el est tr√®s non lin√©aire. 

On observe √©galement une tr√®s faible augmentation de la variance √† mesure que la flexibilit√© augmente. Par cons√©quent, l'**EQM** du test diminue consid√©rablement avant de conna√Ætre une l√©g√®re augmentation lorsque la flexibilit√© du mod√®le augmente.



<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 60%;"
    src="../images/Bizid_au_carre.png" 
    alt="Bizid_au_carre">
</img>

<b>FIG 2.12</b><i> ![Biais au carr√© (courbe bleue), variance (courbe orange), Var(œµ) (ligne pointill√©e) et MSE de test (courbe rouge) pour les trois ensembles de donn√©es des figures 2.9-2.11.  La ligne pointill√©e verticale indique le niveau de flexibilit√© correspondant √† la plus petite EQM de test.](https://www.statlearning.com/)</i>

La relation entre le biais, la variance et l'**EQM** de l'ensemble de test, pr√©sent√©e dans l'√©quation (2.7) et illustr√©e √† la $figure 2.12$, est appel√©e **le compromis biais-variance**. 

**Pour qu'une m√©thode d'apprentissage statistique soit performante sur un ensemble de tests, il faut que la variance et le biais au carr√© soient faibles.** Il s'agit d'un compromis car il est facile d'obtenir une m√©thode avec un biais extr√™mement faible mais une variance √©lev√©e (par exemple, en tra√ßant une courbe qui passe par chaque observation d'apprentissage) ou une m√©thode avec une variance tr√®s faible mais un biais √©lev√© (en ajustant une ligne horizontale aux donn√©es). 

Le d√©fi consiste √† trouver une m√©thode pour laquelle la variance et le biais au carr√© sont tous deux faibles. Dans une situation r√©elle o√π $f$ n'est pas observ√©e, il n'est g√©n√©ralement pas possible de calculer explicitement l'**EQM**, le biais ou la variance d'une m√©thode d'apprentissage statistique. N√©anmoins, il faut toujours garder √† l'esprit le compromis biais-variance. 

Les m√©thodes qui sont extr√™mement flexible  et qui peuvent √©liminer le biais ne garantit pas qu'elles seront plus performantes qu'une m√©thode beaucoup plus simple comme la r√©gression lin√©aire. Pour prendre un exemple extr√™me, supposons que la v√©ritable ${f}$ soit lin√©aire. Dans cette situation, la r√©gression lin√©aire n'aura aucun biais, ce qui rendra tr√®s difficile la concurrence d'une m√©thode plus flexible. En revanche, si la vrai ${f}$ est fortement non lin√©aire et que nous disposons d'un grand nombre d'observations d'apprentissage, nous pouvons obtenir de meilleurs r√©sultats en utilisant une approche tr√®s flexible, comme dans la $figure 2.11$. 

<a name="2-4"/>

## [2.4. Le contexte de la classification](#2-4) ##

[Retour TOC](#toc)

Jusqu'√† pr√©sent, notre discussion sur la pr√©cision des mod√®les s'est concentr√©e sur le cadre de la r√©gression. Cependant, bon nombre des concepts que nous avons rencontr√©s, tels que le compromis biais-variance, sont transpos√©s au cadre de la classification avec seulement quelques modifications dues au fait que $y_i$ n'est plus quantitatif.  

Supposons que nous cherchions √† estimer $f$ sur la base d'observations d'apprentissage ${(x_1,\ y_1),\ .\ .\ .\ (x_n,\ y_n)}$, o√π maintenant $y_1,\ .\ .\ .\ ,\ y_n$ sont qualitatifs. L'approche la plus courante pour quantifier la pr√©cision de notre estimation $\hat{f}$ est le taux d'erreur d'apprentissage, c'est-√†-dire la proportion d'erreurs qui sont commises si nous appliquons notre estimation $\hat{f}$ aux observations d'apprentissage :


$$
\frac{1}{n}\sum_{i=1}^{n}I(y_i \neq \hat{y}_i) \hspace{6 em} (2.8)
$$


Ici $\hat{y}_i$ est l'√©tiquette de classe pr√©dite pour la $i^{√®me}$ observation en utilisant $\hat{f}$. Et $I(y_i\neq \hat{y_i})$ est une variable indicatrice qui est √©gale √† 1 si $y_i\neq\hat{y}_i$ et z√©ro si $y_i=\hat{y}_i$. Si $I(y_i\neq \hat{y_i})=0$ alors la $i^{√®m}$ observation a √©t√© class√©e correctement par notre m√©thode de classification ; sinon elle a √©t√© mal class√©e. 

L'√©quation (2.8) calcule donc la fraction des classifications incorrectes.  L'√©quation (2.8) est appel√©e **taux d'erreur d'apprentissage car elle est calcul√©e sur la base des donn√©es qui ont √©t√© utilis√©es pour entra√Æner notre classificateur**. 

Comme dans le cas de la r√©gression, nous sommes plus int√©ress√©s par les taux d'erreur qui r√©sultent de l'application de notre classificateur aux observations de test qui n'ont pas √©t√© utilis√©es dans la formation.  Le taux d'erreur de test associ√© √† un ensemble d'observations de test de la forme  $(x_0,\ y_0)$ est donn√© par


$$
Ave(I(y_0 \neq \hat{y}_0)), \hspace {6 em} (2.9)
$$


o√π $\hat{y}_0$ est l'√©tiquette de classe pr√©dite qui r√©sulte de l'application du classificateur √† l'observation de test avec le pr√©dicteur $x_0$. Un bon classificateur est celui pour lequel l'erreur de test (2.9) est la plus petite.

<a name="2-5"/>

## [2.5. Le classificateur de Bayes](#2-5) ##

[Retour TOC](#toc)

Il est possible de montrer que le taux d'erreur du test donn√© dans (2.9) est minimis√©, en moyenne, par un classificateur tr√®s simple qui affecte chaque observation √† la classe la plus probable, compte tenu des valeurs de ses pr√©dicteurs. En d'autres termes, nous devrions simplement affecter une observation de test avec **le vecteur pr√©dicteur** $x_0$ √† la classe $j$ pour laquelle


$$
Pr(Y=j|X=x_0) \hspace{6 em} (2.10)
$$


est le plus grand. Notez que (2.10) est une probabilit√© conditionnelle : c'est la probabilit√© que $Y=j$ √©tant donn√© le vecteur pr√©dicteur observ√© $x_0$. Ce classificateur tr√®s simple est appel√© classificateur de Bayes. Dans un probl√®me √† deux classes o√π il n'y a que deux valeurs de r√©ponse possibles, disons la classe 1 ou la classe 2, le classificateur de Bayes correspond √† la pr√©diction de la $classe\ 1$ si $Pr(Y=1|X=x_0)>0.5$, sinon de la $classe\ 2$.  



<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 50%;"
    src="../images/Donnees_Simulees.png" 
    alt="Donnees_Simulees">
</img>

<b>FIG 2.13</b><i> ![Un ensemble de donn√©es simul√© compos√© de 100 observations dans chacun des deux groupes, indiqu√©s en bleu et en orange. La ligne pointill√©e violette repr√©sente la limite de d√©cision de Bayes. La grille de fond orange indique la r√©gion dans laquelle une observation de test sera affect√©e √† la classe orange, et la grille de fond bleue indique la r√©gion dans laquelle une observation de test sera affect√©e √† la classe bleue.](https://www.statlearning.com)</i>

La $figure\ 2.13$ pr√©sente un exemple utilisant un ensemble de donn√©es simul√©es dans un espace bidimensionnel compos√© de pr√©dicteurs $X_1$ et $X_2$. Les cercles orange et bleus correspondent √† des observations de formation qui appartiennent √† deux classes diff√©rentes. Pour chaque valeur de $X_1$ et $X_2$, il existe une probabilit√© diff√©rente que la r√©ponse soit orange ou bleue. 

Comme il s'agit de donn√©es simul√©es, nous savons comment les donn√©es ont √©t√© g√©n√©r√©es et nous pouvons calculer les probabilit√©s conditionnelles pour chaque valeur de $X_1$ et $X_2$. 

- La r√©gion ombr√©e en orange refl√®te l'ensemble des points pour lesquels $Pr(Y=orange|X)$ est sup√©rieur √† 50%, tandis que 
- la r√©gion ombr√©e en bleu indique l'ensemble des points pour lesquels la probabilit√© est inf√©rieure √† 50%. 
- La ligne pointill√©e violette repr√©sente les points pour lesquels la probabilit√© est exactement de 50%. C'est ce qu'on appelle la fronti√®re de d√©cision de Bayes. 

La pr√©diction du classificateur de Bayes est d√©termin√©e par la fronti√®re de d√©cision de Bayes, une observation qui se trouve du c√¥t√© orange de la fronti√®re sera affect√©e √† la classe orange, et de m√™me une observation du c√¥t√© bleu de la fronti√®re sera affect√©e √† la classe bleue.  

**Le classificateur de Bayes produit le taux d'erreur de test le plus faible possible, appel√© taux d'erreur de Bayes**. Puisque le classificateur de Bayes choisira toujours la classe pour laquelle (2.10) est le plus grand, le taux d'erreur sera $1-max_j\ Pr(Y=j|X=x_0)\ avec\ X=x_0$. 

En g√©n√©ral, le taux d'erreur global de Bayes est donn√© par


$$
1-E(max_j Pr(Y=j|X)), \hspace{6 em} (2.11)
$$


o√π **l'esp√©rance est la moyenne de la probabilit√© sur toutes les valeurs possibles de $X$** . Pour nos donn√©es simul√©es, le taux d'erreur de Bayes est de $0.133$. Il est sup√©rieur √† z√©ro, car les classes se chevauchent dans la population r√©elle, de sorte que $\max_j\ Pr(Y=j|X=x_0)<1$ pour certaines valeurs de $x_0$.  **Le taux d‚Äôerreur de Bayes est analogue √† l‚Äôerreur irr√©ductible, discut√©e pr√©c√©demment.**

<a name="2-6"/>

## [2.6 Voisins les plus proches (K-Nearest Neighbors)](#2-6) ##

[Retour TOC](#toc)

En th√©orie, nous aimerions toujours pr√©dire les r√©ponses qualitatives √† l'aide du classificateur de Bayes. Mais pour les donn√©es r√©elles, nous ne connaissons pas la distribution conditionnelle de $Y$ √©tant donn√© $X$, et il est donc impossible de calculer le classificateur de Bayes.  Par cons√©quent, **le classificateur de Bayes sert d'√©talon-or inatteignable pour comparer d'autres m√©thodes.** 

De nombreuses approches tentent d'estimer la distribution conditionnelle de $Y$ √©tant donn√© $X$, puis de classer une observation donn√©e dans la classe dont la probabilit√© estim√©e est la plus √©lev√©e. L'une de ces m√©thodes est le classificateur $KNN (K{-}nearest neighbors)$. 

√âtant donn√© un nombre entier positif $K$ et une observation de test $x_0$, le classificateur $KNN$ identifie d'abord les $K$ points dans les donn√©es d'apprentissage qui sont les plus proches de $x_0$, repr√©sent√©s par $\mathcal{N}_0$. Il estime ensuite la probabilit√© conditionnelle pour la classe $j$ comme la fraction de points dans $\mathcal{N}_0$ dont les valeurs de r√©ponse sont √©gales √† $j$ :


$$
Pr(Y=j|X=x_0)=\frac{1}{k}\sum_I(y_i=j). \hspace{6 em} (2.12)
$$


Enfin, $KNN$ classe l'observation de test $x_0$ dans la classe avec la plus grande probabilit√© de (2.12).  La $figure\ 2.14$ fournit un exemple illustratif de l'approche $KNN$. Dans le panneau de gauche, nous avons trac√© un petit ensemble de donn√©es d'apprentissage compos√© de six observations bleues et de six observations orange. Notre objectif est de faire une pr√©diction pour le point marqu√© par la croix noire. 

Supposons que nous choisissions $K=3$. Donc $KNN$ identifiera d'abord les trois observations qui sont les plus proches de la croix.  Ce voisinage est repr√©sent√© par un cercle. Il se compose de deux points bleus et d'un point orange, ce qui donne des probabilit√©s estim√©es de 2/3 pour la classe bleue et de 1/3 pour la classe orange. $KNN$ pr√©dit donc que la croix noire appartient √† la classe bleue. 

Dans le panneau de droite de la $figure 2.14$, nous avons appliqu√© l'approche $KNN$ avec $K=3$ √† toutes les valeurs possibles de $X_1$ et $X_2$, et nous avons dessin√© la limite de d√©cision $KNN$ correspondante.  Malgr√© le fait qu'il s'agisse d'une approche tr√®s simple, $KNN$ peut souvent produire des classifieurs qui sont √©tonnamment proches du classifieur optimal de Bayes.  

La $figure\ 2.15$ montre la limite de d√©cision $KNN$, en utilisant $K=10$, lorsqu'elle est appliqu√©e √† l'ensemble de donn√©es simul√©es plus important de la $figure\ 2.13$. Remarquez que m√™me si la distribution r√©elle n'est pas connue par le classificateur $KNN$, la limite de d√©cision $KNN$ est tr√®s proche de celle du classificateur Bayes. Le taux d'erreur du test utilisant $KNN$ est de $0.1363$ , ce qui est proche du taux d'erreur de Bayes de $0.1304$ .



<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 50%;"
    src="../images/Approche_KNN.png" 
    alt="Approche_KNN">
</img>



<b>FIG 2.14</b><i> ![L'approche KNN, utilisant K = 3, est illustr√©e dans une situation simple avec six observations bleues et six observations orange. √Ä gauche : une observation test pour laquelle une √©tiquette de classe pr√©dite est souhait√©e est repr√©sent√©e par une croix noire. Les trois points les plus proches de l'observation test sont identifi√©s, et il est pr√©dit que l'observation test appartient √† la classe la plus courante, dans ce cas le bleu. A droite : La limite de d√©cision KNN pour cet exemple est repr√©sent√©e en noir. La grille bleue indique la r√©gion dans laquelle une observation de test sera affect√©e √† la classe bleue, et la grille orange indique la r√©gion dans laquelle elle sera affect√©e √† la classe orange.](https://www.statlearning.com/)</i>



<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 50%;"
    src="../images/Courbe_Noire.png" 
    alt="Approche_KNN">
</img>



<b>FIG 2.15</b><i> ![La courbe noire indique la limite de d√©cision KNN sur les donn√©es de la figure 2.13, avec K = 10. La limite de d√©cision de Bayes est repr√©sent√©e par une ligne pointill√©e violette. Les limites de d√©cision KNN et Bayes sont tr√®s similaires.](https://www.statlearning.com/)</i>

<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 50%;"
    src="../images/Comparaison_Limite.png" 
    alt="Comparaison_Limite">
</img>



<b>FIG 2.16</b><i> ![Comparaison des limites de d√©cision KNN (courbes noires pleines) obtenues avec K = 1 et K = 100 sur les donn√©es de la figure 2.13. Avec K = 1, la limite de d√©cision est trop flexible, tandis qu'avec K = 100, elle n'est pas suffisamment flexible. La limite de d√©cision de Bayes est repr√©sent√©e par une ligne pointill√©e violette.](https://www.statlearning.com/)</i>

Le choix de $K$ a un effet drastique sur le classificateur $KNN$ obtenu.  La $figure\ 2.16$ montre deux ajustements $KNN$ aux donn√©es simul√©es de la $figure\ 2.13$, en utilisant $K=1$ et $K=100$. Lorsque $K=1$, la limite de d√©cision est trop flexible et trouve des mod√®les dans les donn√©es qui ne correspondent pas √† la limite de d√©cision de Bayes. Cela correspond √† un classificateur qui a un faible biais mais une variance tr√®s √©lev√©e. Au fur et √† mesure que $K$ augmente, la m√©thode devient moins flexible et produit une limite de d√©cision qui est proche de la lin√©arit√©. Cela correspond √† un classificateur √† faible variance mais √† biais √©lev√©. 

Sur cet ensemble de donn√©es simul√©es, ni $K=1$ ni $K=100$ ne donnent de bonnes pr√©dictions : ils ont des taux d'erreur de test de 0.1695 et 0.1925, respectivement.  Juste comme dans le cadre de la r√©gression, il n'y a pas de relation forte entre le taux d'erreur de formation et le taux d'erreur de test. Avec $K=1$, le taux d'erreur de formation de $KNN$ est de 0, mais le taux d'erreur de test peut √™tre assez √©lev√©. 

**En g√©n√©ral, √† mesure que nous utilisons des m√©thodes de classification plus flexibles, le taux d'erreur d'apprentissage diminue, mais pas le taux d'erreur de test**. Dans la $figure\ 2.17$, nous avons trac√© les erreurs de test et d'apprentissage de $KNN$ en fonction de $1/K$. **Plus $1/K$ augmente, plus la m√©thode devient flexible. Comme dans le cadre de la r√©gression, le taux d'erreur d'apprentissage diminue syst√©matiquement √† mesure que la flexibilit√© augmente.** Cependant, l'erreur de test pr√©sente une forme en $\bigcup$ caract√©ristique, diminuant d'abord (avec un minimum √† environ $K=10$) avant d'augmenter √† nouveau lorsque la m√©thode devient excessivement flexible et qu'elle se surestime(overfitting).



<img 
    style="display: block; 
           margin-left: auto;
           margin-right: auto;
           width: 50%;"
    src="../images/Taux_Erreur_KNN.png" 
    alt="Taux_Erreur_KNN">
</img>





<b>FIG 2.16</b><i> ![Le taux d'erreur de formation KNN (bleu, 200 observations) et le taux d'erreur de test (orange, 5 000 observations) sur les donn√©es de la figure 2.13, √† mesure que le niveau de flexibilit√© (√©valu√© √† l'aide de 1/K sur l'√©chelle logarithmique) augmente, ou de mani√®re √©quivalente √† mesure que le nombre de voisins K diminue. La ligne pointill√©e noire indique le taux d'erreur de Bayes. L'irr√©gularit√© des courbes est due √† la petite taille de l'ensemble de donn√©es d'apprentissage.](https://www.statlearning.com/)</i>

**Dans le cadre de la r√©gression et de la classification, le choix du niveau de flexibilit√© correct est essentiel au succ√®s de toute m√©thode d'apprentissage statistique.  Le compromis biais-variance, et la forme en U de l'erreur de test qui en r√©sulte, peuvent rendre cette t√¢che difficile.** 

**Diverses m√©thodes permettent d'estimer les taux d'erreur de test et ainsi choisir le niveau optimal de flexibilit√© pour une m√©thode d'apprentissage statistique donn√©e.**
