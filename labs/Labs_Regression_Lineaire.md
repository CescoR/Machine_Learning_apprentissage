# Section Laboratoires 1 : La r√©gression lin√©aire #

[Retour README](../README.md)

[[4]](https://machinelearnia.com/apprendre-le-machine-learning-en-une-semaine/) La r√©gression lin√©aire est un outil utile pour pr√©dire une r√©ponse quantitative. 

Mais avant d'aller plus loin, revenons sur ce qu'est le Machine Learning. Le Machine Learning consiste √† laisser l‚Äôordinateur apprendre quel calcul effectuer, plut√¥t que de lui donner ce calcul (c‚Äôest-√†-dire le programmer de fa√ßon explicite).

C'est une d√©finition donn√©e par Arthur Samuel, 1959 (un math√©maticien am√©ricain qui a d√©velopp√© un programme pouvant apprendre tout seul comment jouer aux Dames en 1959.) *"L'apprentissage automatique est la science qui consiste d'amener les ordinateurs √† apprendre sans √™tre explicitement programm√©s."*

Ensuite, Tom Mitchell donna en 1998 une d√©finition un peu plus moderne du Machine Learning en √©non√ßant "...*qu‚Äôune machine apprend quand sa performance √† faire une certaine t√¢che s‚Äôam√©liore avec de nouvelles exp√©riences.*"

<a name="toc"/>

[1.1 Capacit√© d'apprendre](#1-1)

[1.2 L'apprentissage supervis√©](#1-2)

- [1.2.1 Le Dataset](#1-2-1)

- [1.2.2 Le Mod√®le](#1-2-2)

- [1.2.3 Apprentissage](#1-2-3)

  - [1.2.3.1 Les applications de l'apprentissage supervis√©](#1-2-3-1)

  - [1.2.3.2 D√©finir la fonction de co√ªt](#1-2-3-2)

- [1.2.4 Les param√®tres qui minimisent la fonction de co√ªt](#1-2-4)

[1.3 Les 4 notions clefs du Machine Learning sur la R√©gression Lin√©aire](#1-3)

[1.4 Les √©tapes pour programme de R√©gression Lin√©aire](#1-4)

- [1.4.1 Importer les librairies et les fonctions](#1-4)

- [1.4.2 Cr√©er les Dataset](#1-4)

- [1.4.3 D√©velopper le mod√®le et l'entra√Æner](#1-4)

[1.5 Les courbes d'apprentissages](#1-5)

- [1.5.1 Importer les librairies et les fonctions](#1-5-1)

- [1.5.2 G√©n√©rer le Dataset al√©atoire](#1-5-2)

- [1.5.3 Le Mod√®le](#1-5-3)

- [1.5.4 La Fonction co√ªt](#1-5-4)

- [1.5.5 Gradient et Descente de gradient](#1-5-5)

- [1.5.6 Phase d'apprentissage](#1-5-6)

- [1.5.7 Courbe d'apprentissage](#1-5-7)

- [1.5.8 Coefficient de d√©termination](#1-5-8)

<a name="1-1"/>

## [1.1 Capacit√© d'apprendre](#1-1) ##

[Retour TOC](#toc)

Les scientifiques se sont inspir√©s de la m√©thode d'apprentissage des √™tres humains pour donner √† un ordinateur la capacit√© d'apprendre.

Parmis les m√©thodes apprentissages, voici celles qui nous int√©ressent dans le Machine Learning :

1. L'apprentissage supervis√© (Supervised Learning)
2. L'apprentissage non supervis√© (Unserpivised Learning)
3. L'apprentissage par renforcement (Reinforcement Learning)

<a name="1-2"/>

## [1.2 L'apprentissage supervis√©](#1-2) ##

[Retour TOC](#toc)

L'apprentissage supervis√©e est la m√©thode qui fournit un grand nombre d'exemples √† la machine pour son apprentissage.

Les quatre notions fondamentales du Machine Learning sont :

1. Le Dataset
2. Le Mod√®le avec ses Param√®tres
3. Une Fonction de Co√ªt
4. L'Algorithme d'Apprentissage

<a name="1-2-1"/>

### [1.2.1 Le Dataset](#1-2-1) ###

[Retour TOC](#toc)

On parle d'apprentissage supervis√© lorsque l'on fournit √† la machine un ensemble de donn√©es apprentissages appel√© le Dataset.
Ces exemples fournis √† la machines  sont repr√©sent√©s par la couple ($X$, $y$) et le but est de faire apprendre √† la machine la relation qui relie $X$ √† $y$.

En Machine Learning (**ML**), les couples ( $X$, $y$ ) de donn√©es peuvent √™tre repr√©sent√©es dans un tableau, avec

- la variable $x$ (appel√©e feature) qui influence la valeur  de la variable $y$. En g√©n√©ral, nous pouvons avoir une grande quantit√© de features repr√©sent√© par l'ensemble $\lbrace x_1, x_2,...,x_p\rbrace$ que l'on regroupe dans une matrice $X$, avec $p$ le nombre des variables du Dataset.
- la variable $y$ (appel√©e target) est la variable que l'on cherche √† pr√©dire.

Par exemple, un Dataset reprenant des appartements √† vendre avec leur prix $y_m$  (avec $m$ le nombre d'appartement observ√©s) et les features $x_1$ = surface en $m^2 $, $x_2$ = nombre de chambres et $x_3$ = qualit√© des mat√©riaux qui influencent ce prix $y_m$.

| $y$ (target) = prix | $x_1$ (feature) = Surface en $m^2$ | $x_2$ (feature) = N chambres | $x_3$ (feature) = Qualit√© |
| :-----------------: | :--------------------------------: | :--------------------------: | :-----------------------: |
|      655 000 ‚Ç¨      |                180                 |              5               |            2.5            |
|      555 000 ‚Ç¨      |                160                 |              4               |             2             |
|      450 000 ‚Ç¨      |                140                 |              3               |             2             |
|      350 000 ‚Ç¨      |                140                 |              3               |             1             |
|     3000 000 ‚Ç¨      |                125                 |              3               |            1.5            |

Donc, en Machine Learning, on dispose de $m$ d'appartements et on d√©signe 

- $x^{(i)}$  ou $x_i$ la surface habitable de l'exemple $i$
- $y^{(i)}$  ou $y_i$ le prix de vente de l'exemple $i$

En visualisant le Dataset, nous avons le nuage de point suivant :

![Labs_Modele_Lineaire](../images/Labs_Modele_Lin√©aire_DS.png)



Dans la pratique, on exprime notre Dataset et nos param√®tres sous forme matricielle, ce qui simplifie beaucoup les calculs.  un vecteur $y \in \mathbb R^{m\times 1}$ et une matrice $X \in \mathbb R^{m\times n}$ qui inclut toutes les features $n$. Dans la r√©gression lin√©aire, ùíè = ùüè. Voir appendice [[A]](../docs/Appendice_Mathematique.md#A)

<a name="1-2-2"/>

### [1.2.2 Le Mod√®le](#1-2-2) ###

[Retour TOC](#toc)

Pour l'apprentissage automatique, √† partir de ce Dataset, nous allons construire un Mod√®le. 

| Mod√®le Lin√©aire                                             |
| ----------------------------------------------------------- |
| ![Labs_Modele_Lineaire](../images/Labs_Modele_Lineaire.png) |
| $f(x)=ax + b$                                               |

Avec $a\ et\ b$ les **param√®tres** du mod√®le.

Dans cet exemple, nous allons construire un mod√®le lin√©aire $f(x)=ax +b$ o√π $a\ et\ b$ sont les param√®tres du mod√®le. Une chose important √† noter est qu'un mod√®le retourne des erreurs par rapport au Dataset. On appelle **Fonction de co√ªt** l'ensemble de ces erreurs  et le plus souvent, on prend la moyenne quadratique de ces erreurs.

<a name="1-2-3"/>

### [1.2.3 Apprentissage](#1-2-3) ###

[Retour TOC](#toc)

<a name="1-2-3-1"/>

#### [1.2.3.1 Les applications de l'apprentissage supervis√©](#1-2-3-1) ####

[Retour TOC](#toc)

L'apprentissage supervis√© permet de r√©soudre, par exemple, deux types de probl√®mes :

- Les probl√®mes de **R√©gression**. On cherche √† pr√©dire la valeur d'une variable continue c'est √† dire une variable qui peut prendre une infinit√© de valeur. Pa exemple, pr√©dire le prix d‚Äôun appartement $(y)$ selon sa surface habitable $(x)$.
- Les probl√®mes de **Classification**. On cherche √† classer un objet dans diff√©rentes classes c'est √† dire que l'on cherche √† pr√©dire la valeur d'une variable discr√®te (qui ne prend qu'un nombre fini de valeurs). Par exemple, pr√©dire si un email est un spam ( $classe\ y = 1$ ) ou non
  ( $classe y = 0$ ) selon le nombre de liens pr√©sent dans l‚Äôemail ( $x$ ). Autre exemple, pr√©dire si une tumeur est maligne ( $y=1$ ) ou b√©nigne ( $y=0$ )  selon la taille de la tumeur ( $x_1$ ) et l‚Äô√¢ge du patient ( $x_2$ ).

![Labs_Modele_Lineaire](../images/Labs_Modele_Regression_Classification.png)

La force du Machine Learning, c‚Äôest qu‚Äôil est tr√®s facile de d√©velopper des mod√®les tr√®s complexes qui peuvent analyser des milliers de features ( $x$ )
qu‚Äôun √™tre humain ne serait pas capable de prendre en compte pour faire son calcul.

<a name="1-2-3-2"/>

#### [1.2.3.2 D√©finir la fonction de co√ªt](#1-2-3-2) ####

[Retour TOC](#toc)



![Labs_Modele_Lineaire](../images/Labs_Modele_Lin√©aire_FC.png)

Un bon mod√®le donne de petites erreurs entre ses pr√©dictions $f(x)$ et les exemples $( y )$ du Dataset.
Nous ne connaissons pas les valeurs des param√®tres $a\ et\ b$, ce sera le r√¥le de la machine de les trouver, de sorte √† tracer un mod√®le qui s‚Äôins√®re bien dans notre nuage de point comme ci-dessus.

Pour la r√©gression lin√©aire, on utilise la norme euclidienne pour mesurer les erreurs entre $f(x)$ et $ (y) $.
Concr√®tement, voici la formule pour exprimer l‚Äôerreur $i$ entre le prix $y_i$ et la pr√©diction faites en utilisant la surface $x_i$ :




$$
erreur_i = (f(x_i) - y_i)^2
$$




Par exemple, soit le $10^{i√®me}$ exemple du Dataset qui est un appartement de $x_{10} = 80\ m^2$ dont le prix s‚Äô√©l√®ve √†  $y_{10}=100 000$ ‚Ç¨ et que le mod√®le pr√©dise un prix de $f(x_{10}) = 100002$ ‚Ç¨. L‚Äôerreur pour cette exemple est donc : 




$$
ùëíùëüùëüùëíùë¢ùëü_{10} = ( ùëì(ùë•_{10}) ‚àí ùë¶_{10})^2 = ( 100002 ‚àí100000 )^2 = 4
$$


Et comme chaque pr√©diction s‚Äôaccompagne d‚Äôune erreur, on a donc $m$ erreurs. 

On d√©finit la Fonction Co√ªt $J(a,\ b)$ comme √©tant la moyenne de toutes les erreurs :




$$
J(a, b) = \frac{1}{2m} \sum_{i=1}^m (f(x_i) - y_i)^2 \hspace{3 em} avec\ erreur_i = (f(x_i) - y_i)^2
$$




c‚Äôest l‚Äôerreur **quadratique moyenne (Mean Squared Error).**

![Labs_Modele_Lineaire](../images/Labs_Erreur_Quadratique.png)

Et donc la fonction de co√ªt devient :




$$
J(a, b) = \frac{1}{2m} \sum_{i=1}^m (b + ax_i - y_i)^2
$$





<a name="1-2-4"/>

### [1.2.4 Les param√®tres qui minimisent la fonction de co√ªt](#1-2-4) ###

[Retour TOC](#toc)

L'objectif principal de l'apprentissage supervis√© est de trouver les param√®tres $a\ et\ b$ du mod√®le qui minimisent la fonction de co√ªt. Pour y arriver, nous allons utiliser un algorithme d'apprentissage et l'exemple le plus courant √©tant l'algorithme du **Gradient Descent.**

**Comprendre le Gradient Descent (la descente de gradient)**
[[4]](https://machinelearnia.com/apprendre-le-machine-learning-en-une-semaine/ ) Imaginez-vous perdu en montagne. Votre but est de rejoindre le refuge qui se trouve au point le plus bas de la vall√©e. Vous n‚Äôavez pas pris de carte avec vous donc vous ne connaissez pas les coordonn√©es de ce refuge, vous devez le trouver tout seul.

Pour vous en sortir, voici une strat√©gie √† adopter :
1. Depuis votre position actuelle, vous partez en direction de l√† o√π la pente descend le plus fort.
2. Vous avancez une certaine distance en suivant cette direction co√ªte que co√ªte (m√™me si √ßa implique de remonter une pente)
3. Une fois cette distance parcourue, vous r√©p√©tez les 2 premi√®res op√©rations en boucle, jusqu‚Äô√† atteindre le point le plus bas de la vall√©e.

![Labs_Modele_Lineaire](../images/Labs_Gradiant_Descent.png)

Les √©tapes 1, 2 et 3 forment ce qu‚Äôon appelle l‚Äôalgorithme de Gradient Descent.
Cet algorithme vous permet de trouver le minimum de la Fonction Co√ªt  $J(a,b)$ (le point le plus bas de la montagne) en partant de coordonn√©es $a$ et $b$ al√©atoires (votre position initiale dans la montagne).

Doncn l'algorithme de descente de gradient consiste √† 

1. calculer la pente de la Fonction Co√ªt, c‚Äôest-√†-dire la d√©riv√©e de $J(a, b)$ .
2. √©voluer d‚Äôune certaine distance $\alpha$ dans la direction de la pente la plus forte. Cela a pour r√©sultat de modifier les param√®tres $a$ et $b$
3. recommencer les √©tapes 1 et 2 jusqu‚Äô√† atteindre le minimum de $J(a,b)$.

Pour illustrer l‚Äôalgorithme, voyez le dessin ci-dessous, o√π nous voyons la recherche du param√®tre $a$ id√©al (la m√™me chose s‚Äôapplique au param√®tre $b$ )



![Labs_Modele_Lineaire](../images/Labs_Calcul_Gradiant_Descent.png)

**Comment utiliser l‚Äôalgorithme de Gradient Descent?** Nous avons jusqu‚Äô√† pr√©sent cr√©√© un Dataset, d√©velopp√© un mod√®le aux param√®tres inconnus, et exprim√© la Fonction Co√ªt  $J(a, b)$ associ√©e √† ce mod√®le. Notre objectif final : Trouver les param√®tres $a$ et $b$ qui minimisent $J(a, b)$.

Pour cela, nous allons choisir $a$ et $b$ au hasard, puis nous allons utiliser en boucle la descente de gradient pour mettre √† jour nos param√®tres dans la direction de la Fonction Co√ªt la plus faible.

R√©p√©ter en boucle :




$$
a = a - \alpha \frac{\partial J(a, b)}{\partial a}
$$



$$
b = b - \alpha \frac{\partial J(a, b)}{\partial b}
$$



A chaque it√©ration de cette boucle, les param√®tres $a$ et $b$ sont mis √† jour en soustrayant leur propre valeur √† la valeur de la pente $\frac{\partial J(a, b)}{\partial ...}$
multipli√©e par la distance √† parcourir $\alpha$. On appelle $\alpha$ **la vitesse d‚Äôapprentissage (Learning rate)**.

Si la vitesse est trop lente, le mod√®le peut mettre longtemps √† √™tre entra√Æn√©, mais si la vitesse est trop grande, alors la distance parcourue
est trop longue et le mod√®le peut ne jamais converger. **Il est important de trouver un juste milieu. Le dessin ci-dessous illustre mes propos.**

![Labs_Modele_Lineaire](../images/Labs_Vitesse_Gradiant_Descent.png)

L' algorithme arrive √† minimiser la Fonction Co√ªt avec le nombre d‚Äôit√©rations. Par exemple, Une fois cet algorithme programm√©, nous pouvons laisser la machine apprendre √† pr√©dire le prix d‚Äôun appartement selon sa surface habitable. 

<a name="1-3"/>

## [1.3 Les 4 notions clefs du Machine Learning sur la Regression Lin√©aire](#1-3)  ##

[Retour TOC](#toc)

Le Machine Learning est un domaine vaste et complexe et 4 notions essentielles sont √† retenir.

- Le **Dataset** . En Machine Learning, tout d√©marre d‚Äôun Dataset qui contient les donn√©es. Dans l‚Äôapprentissage supervis√©, le Dataset contient les questions $X$ et les r√©ponses $y$ au probl√®me que la machine doit r√©soudre. Donc, nous devons r√©colter les donn√©es $(X, y)$ avec $X, y \in \mathbb R ^{m\times1}$

- Le **Mod√®le** et ses **param√®tres**. A partir de ce Dataset, on cr√©e un mod√®le, qui n‚Äôest autre qu‚Äôune fonction math√©matique. Les coefficients de cette fonction sont les param√®tres du mod√®le. Ici, donner √† la machine un mod√®le lin√©aire $F(X) = X . \theta$ 

  o√π 




$$
\theta = \begin{pmatrix} 
a \\ 
b \
\end{pmatrix}
$$




- La **Fonction Co√ªt**. Lorsqu‚Äôon teste le mod√®le sur le Dataset, celui-ci nous donne des erreurs et l‚Äôensemble de ces erreurs donne la Fonction Co√ªt. 




$$
J(\theta) = \frac{1}{2m}\sum (F(X)-y)^2
$$




- L‚Äô**Algorithme d‚Äôapprentissage** L‚Äôid√©e centrale du Machine Learning, c‚Äôest de laisser la machine trouver quels sont les param√®tres de notre mod√®le qui minimisent la Fonction Co√ªt.

  Donc r√©p√©ter en boucle :




$$
\theta = \theta - \alpha \times \frac{\partial J(\theta)}{\partial \theta}
$$




avec le gradient qui vaut : $\frac{\partial J(\theta)}{\theta} = \frac{1}{m}X^T . (F(X)-y)$. Voir Appendice [[B]](../docs/Appendice_Mathematique.md#b)

<a name="1-4"/>

## [1.4 Les √©tapes pour programme de R√©gression Lin√©aire](#1-4) ##

[Retour TOC](#toc)

[Labs_1_Regression_Lineaire](../codes/Labs_1_Regression_Lineaire.ipynb)

<a name="1-4-1"/>

### [1.4.1 Importer les librairies et les fonctions](#1-4-1) ###

[Retour TOC](#toc)

- **Numpy** : pour manipuler le Dataset comme une matrice
- **Matplotlib.pyplot** : pour visualiser les donn√©es
- La fonction **make_regression SkLearn** : qui permet de simuler des donn√©es en g√©n√©rant un nuage de points
- **SGDRegressor** (qui signifie Stochastic Gradient Descent Regressor) :  qui contient le calcul de la Fonction Co√ªt, des gradients, de l‚Äôalgorithme de minimisation.

```python
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn.datasets import make_regression 
from sklearn.linear_model import SGDRegressor
```

<a name="1-4-2"/>

### [1.4.2 Cr√©er les Dataset](#1-4-2) ###

[Retour TOC](#toc)

Pour ce premier code, nous allons g√©n√©rer un tableau de donn√©es $(x,y)$ al√©atoires. La fonction **make_regression** prend comme arguments 

1. **le nombre d‚Äô√©chantillons √† g√©n√©rer**, 
2. **le nombre de variables** et 
3. **le bruit**. 

Pour maitriser l‚Äôal√©atoire, on √©crit la ligne **np.random.seed(0)**. 

```python
np.random.seed(0)
```

Ensuite,  nous retournons deux vecteurs $x$ et $y$.

```python
x, y = make_regression(n_samples=100, n_features=1, noise=10)
```

Finalement, pour visualiser les donn√©es, on utilise la fonction **plt.scatter$(x, y)$**.

```python
plt.scatter(x, y)
```

Et le r√©sultat afficher du Dataset est

![Labs_Modele_Lineaire](../images/Labs_1_Dataset.png)

<a name="1-4-3"/>

### [1.4.3 D√©velopper le mod√®le et l'entrainer](#1-4-3) ###

[Retour TOC](#toc)

Nous cr√©ons le mod√®le avec $SGDRegressor$ en entrant le nombre d‚Äôit√©rations que le Gradient Descent doit effectuer ainsi que le Learning Rate.

Par exemple, entra√Ænons notre mod√®le sur 100 it√©rations avec un Learning rate de 0.0001.

```python
model = SGDRegressor(max_iter=100, eta0=0.0001)
```

Pour entra√Æner le mod√®le, nous utilisons la fonction $fit()$

```python
model.fit(x,y)
```




$$
\color{red}{!!!Attention!!!\ La\ fonction\ SGDRegressor,\ nous\ pr√©vient\ par\ un\ warning\ que\ nous\ avons\ mal\ configurer\ notre\ mod√®le.}
$$



$$
\color{red}{ConvergenceWarning}:
$$



$$
\ Nombre\ maximal\ d'it√©rations\ atteint\ avant\ la\ convergence.\ Envisager\ d'augmenter\ maxiter\ pour am√©liorer\ l'ajustement
$$




Et ce warning est confirmer par l'observation de la pr√©cision du mod√®le en utilisant la fonction $score$ qui calcule **le coefficient de d√©termination $(R^2)$**  entre le mod√®le et les valeurs $y$ de notre Dataset.

```
print('Coeff R2 =', model.score(x, y))
```

Le r√©sulta $R^2$ est 

```python
Coeff R2 = 0.22279377204565387
```

On peut aussi utiliser notre mod√®le pour faire de nouvelles pr√©dictions avec la fonction $predict$ et tracer ces r√©sultats avec la fonction $plt.plot$.

```python
plt.scatter(x, y) 
plt.plot(x, model.predict(x), c='red', lw = 3)
```

Et le r√©sultat afficher est

![Labs_Modele_Lineaire](../images/Labs_1_Mauvais_Modele.png)



Ce qui confirme que notre mod√®le semble vraiment mauvais. Cela provient d'un manque d' entra√Ænement du mod√®le et  le **Learning Rate** est trop faible. 

Il est possible de le r√©-entra√Æner avec de meilleurs hyper-param√®tres. En Machine Learning, les valeurs qui fonctionnent bien pour la plupart des entra√Ænements sont :

- **Nombre d‚Äôit√©rations** = 1000
- **Learning Rate** = 0.001

```python
model = SGDRegressor(max_iter=1000, eta0=0.001)
model.fit(x,y)
```

Le message retourn√© par le fonction confirme le bon choix de nos hyper-param√®tres.

```python
SGDRegressor(eta0=0.001)
```

Affichons le r√©sultat.

```python
Coeff R2 = 0.9416557905990657
```

![Labs_Modele_Lineaire](../images/Labs_1_Bon_Modele.png)

Notre mod√®le fonctionne vraiment bien avec un coefficient $R^2=94$ %. Ce mod√®le pourrait servir pour faire de bonnes pr√©dictions. Par exemple,  pour pr√©dire le prix d‚Äôun appartement selon sa surface habitable, ou bien pour pr√©dire l‚Äô√©volution de la temp√©rature sur Terre. 

<a name="1-5"/>

## [1.5 Les courbes d'apprentissages](#1-5) ##

[Retour TOC](#toc)

[Labs_1_Regression_Lin√©aire et courbes d'apprentissages](../codes/Labs_1_Regression_Lineaire_Courbes_Apprentissages.ipynb)

En Machine Learning, on appelle courbe d‚Äôapprentissage (Learning curves) les courbes qui montrent l‚Äô√©volution de la Fonction Co√ªt au fil des it√©rations de Gradient Descent. Si votre mod√®le apprend, alors sa Fonction Co√ªt doit diminuer avec le temps, comme ci-dessous.

L'id√©e ici est de voir comment la machine a appris les param√®tres du mod√®le avec le Gradient Descent et pour cela, il existe ce qu‚Äôon appelle les courbes d‚Äôapprentissage.

<a name="1-5-1"/>

### [1.5.1 Importer les librairies et les fonctions](#1-5-1) ###

[Retour TOC](#toc)

Nous importons les librairies et les fonction
- **Numpy** : pour manipuler le Dataset comme une matrice
- **Matplotlib.pyplot** : pour visualiser les donn√©es
- La fonction make_regression SkLearn : qui permet de simuler des donn√©es en g√©n√©rant un nuage de points

```python
import numpy as np 
import matplotlib.pyplot as plt 
from sklearn.datasets import make_regression
```

<a name="1-5-2"/>

### [1.5.2 G√©n√©rer le Dataset al√©atoire](#1-5-2) ###

[Retour TOC](#toc)

La fonction **make_regression** prend comme arguments 

1. **le nombre d‚Äô√©chantillons √† g√©n√©rer**, 
2. **le nombre de variables** et 
3. **le bruit**. 

Pour maitriser l‚Äôal√©atoire, on √©crit la ligne **np.random.seed(4)**. 

```python
np.random.seed(4) 
n = 1 
m = 100 
```

Ensuite,  nous retournons deux vecteurs $x$ et $y$.

```python
x, y = make_regression(n_samples=m, n_features=n, noise=10) 
y = y + 100 
```

Finalement, pour visualiser les donn√©es, on utilise la fonction **plt.scatter$(x, y)$**.

```python
plt.scatter(x, y)
```

Et le r√©sultat afficher du Dataset est

![Labs_Modele_Lineaire](../images/Labs_1_Courbes_Apprentissage_DS.png)

Nous devons utiliser la fonction $reshape()$ car la fonction make_regression ne d√©finit pas correctement toutes les dimensions de $ y.X = (100,1) $ et $y=(100,) $. A la suite du reshape,  $y = (100,1)$

```python
y = y.reshape(y.shape[0], 1) 
```

Nous devons construire notre matrice X avec la colonne de biais c'est √† dire une colonne ne contenant que des 1.




$$
X = 
 \begin{pmatrix}
  x_{1} & 1\\
  x_{2} & 1\\
  \vdots \\
  x_{m} & 1 
 \end{pmatrix}
$$




avec $m$, le nombre de ligne.

Nous utilisons la fonction $hstack()\ de\ Numpy$ qui permet de coller deux vecteurs ensembles. Ici le vecteur X et la matrice colonne 1. La fonction $np.ones()$ cr√©e un vecteur de m√™me dimension que X (lignes et colonnes). Et pour finir, on redimensionne le vecteur X, nous avons bien une matrice X de dimension 2.

```python
X = np.hstack((np.ones(x.shape), x)) 
X.shape
```

Nous allons initialiser un vecteur 





$$
\theta = 
 \begin{pmatrix}
  a \\
  b \\   
 \end{pmatrix}
$$








qui caract√©rise notre mod√®le. On ne conna√Æt pas ce vecteur. Et c'est √† la machine de d√©terminer l'erreur la plus petite c'est √† dire qui minimalise la fonction co√ªt. Et au d√©part, nous initialisons $\theta$ avec des param√®tres al√©atoires.

```python
np.random.seed(0) 
theta = np.random.randn(2, 1)
theta.shape
```

<a name="1-5-3"/>

### [1.5.3 Le Mod√®le](#1-5-3)

[Retour TOC](#toc)

Nous cr√©ons notre mod√®le $F = X . \theta$. Donc nous cr√©ons une fonction mod√®le() qui retourne le produit matriciel de X par $\theta$ car pour rappel  $\theta$ est de dimension (2,1) et $X$ est de dimension (100, 2) donc (100,2) $\times$ (2,1).

```python
def model (X, theta):
    return X.dot(theta)
```

Affichons pour v√©rifier ce que cela nous donne.

```python
theta
plt.scatter(x,y)
plt.plot (X, model(X,theta), c='r')
```

![Labs_Modele_Lineaire](../images/Labs_1_Courbes_Apprentissage_model.png)

Nous voyons clairement qu'avec un $\theta$ al√©atoire, nous avons un tr√®s mauvais mod√®le.

<a name="1-5-4"/>

### [1.5.4 La Fonction co√ªt](#1-5-4) ###

[Retour TOC](#toc)

Nous allons maintenant calculer la fonction co√ªt qui est l'erreur quadratique moyenne.




$$
J(\theta) = \frac{1}{2m}\sum (X . \theta -y)^2
$$





Nous cr√©ons une fonction co√ªt qui a comme param√®tre $x, y$ et $\theta$. Nous utilisons aussi une variable $m$ qui est le nombre d'exemples dans le Dataset, par exemple la longueur du vecteur $y$ (nous aurions aussi pu prendre la longueur de $x$ ). Pour rappel, nous sommons la diff√©rence entre le mod√®le et $y$.

```python
def fonction_cout(X, y, theta):
    m = len(y)
    return (1 / (2 * m)) * np.sum((model(X,theta)-y)**2) 
```

<a name="1-5-5"/>

### [1.5.5 Gradient et Descente de gradient](#1-5-5) ###

[Retour TOC](#toc)

Nous allons calculer la descente de gradient




$$
$\frac{\partial J(\theta)}{\theta} = \frac{1}{m}X^T . (X . \theta - Y)
$$





Nous d√©finissons une fonction gradient qui a comme param√®tre $x,y$ et $\theta$. ous utilisons aussi une variable $m$ qui est le nombre d'exemples dans le Dataset, par exemple la longueur du vecteur $y$. Comme X est un vecteur, X.T (fonction T) permet de transposer X et X.T.dot(...) permet de faire le produit matricielle entre X et la diff√©rence du mod√®le avec Y.

```python
def gradient(X,y,theta):
    m = len(y)
    return (1 / m) * X.T.dot(model(X, theta) - y) 
```

<a name="1-5-6"/>

### [1.5.6 Phase d'apprentissage](#1-5-6) ###

[Retour TOC](#toc)

Maintenant nous avons dans notre bo√Æte √† outil :
1. la fonction de co√ªt
2. la fonction gradient
3. la fonction descente de gradient
4. $x , y$ et $\theta$ initialis√©es al√©atoirement
5. et le mod√®le

Donc nous pouvons calculer un $\theta$ final qui minimisera la fonction de co√ªt.

```python
theta_final = desc_gradient(X,y,theta,learning_rate=0.001,n_iterations=1000)
```

Nous allons v√©rifier si le vecteur param√®tre $\theta$, nous donne de bon r√©sultat. Nous allons cr√©er un vecteur pr√©diction qui est √©gal au r√©sultat du mod√®le ( $X $ par theta_final). Et nous affichons notre Dataset et le vecteur pr√©diction.

```python
predictions = model (X, theta_final)
plt.scatter(x,y)
plt.plot(x,predictions, c='r')
```

![Labs_Modele_Lineaire](../images/Labs_1_Courbes_Apprentissage_Fonction_Cout_Aleatoire.png)

On voit que l'apprentissage n'est pas termin√©. Donc, nous devons soit  augmenter le nombre d'it√©ration c'est √† dire faire travailler la machine plus longtemps ou soit augmenter le learning_rate c'est √† dire que dans la descente de gradient du moment, nous faisons de trop petits pas et  nous allons augmenter la taille. 

```python
iterations = 1000
learning_rate = 0.01

theta_final = desc_gradient(X,y,theta,learning_rate=learning_rate,n_iterations=iterations)
predictions = model (X, theta_final)
plt.scatter(x,y)
plt.plot(x,predictions, c='r')
```

![Labs_Modele_Lineaire](../images/Labs_1_Courbes_Apprentissage_Fonction_Cout_optimise.png)

Ce qui est beaucoup mieux.

<a name="1-5-7"/>

### [1.5.7 Courbe d'apprentissage](#1-5-7) ###

[Retour TOC](#toc)

Maintenant nous arrivons nos courbes d'apprentissages c'est √† dire comment tracer la minimalisation de la fonction de co√ªt.
Nous allons v√©rifier si la machine a bien appris.

Nous allons changer l'algorithme de Descente de gradient, en ajoutant une tableau cost_history initialiser √† z√©ro et ensuite on enregistre, dans le tableau, le co√ªt du mod√®le √† chaque it√©ration.

```python
def desc_gradient(X,y,theta,learning_rate, n_iterations):
    cost_history = np.zeros (n_iterations)
    
    for i in range(0, n_iterations):
        #mettre √† jour theta en disans qu'il est √©gale √† [lui-m√™me - (le learning_rate multipli√© par le gradient)]
            theta = theta - (learning_rate * gradient(X,y,theta))
            cost_history [i] = fonction_cout(X, y, theta)
    return theta, cost_history   
```

```python
theta_final, cost_history = desc_gradient(X,y,theta,learning_rate=learning_rate,n_iterations=iterations)
```

Nous allons tracer notre courbe d'apprentissage.

```python
fig,ax = plt.subplots(figsize=(12,8))  
ax.set_ylabel('J(Theta)')  
ax.set_xlabel('Iterations')  
_=ax.plot(range (iterations),cost_history)
```

![Labs_Modele_Lineaire](../images/Labs_1_Courbes_Apprentissage_Courbe_d'apprentissage.png)

On voit la minimisation de la fonction co√ªt sur les 1000 it√©rations.

Il est √©vident que le machine n'apprend plus entre 200 et 300 it√©rations. Donc, nous pouvons √† ce stade changer n_it√©rations de 1000 √† 300 pour optimiser le processus.

<a name="1-5-8"/>

### [1.5.8 Coefficient de d√©termination](#1-5-8) ###

[Retour TOC](#toc)

Nous allons √©valuer le co√ªt de coefficient de d√©termination. Pour √©valuer la performance d'un mod√®le de R√©gression Lin√©aire, on peut utiliser le coefficient de d√©termination $R^2$. Pour rappel,




$$
R^2 = 1 - \frac{\sum(y - f(x))^2}{\sum(y -\bar{y})^2}
$$





Ce qui donne la performance du mod√®le.Plus $R^2$ est proche de 1 et plus mod√®le est proche de l'ensemble du Dataset. Nous allons cr√©er une fonction coef_determination() avec deux variables. Avec u = r√©sidu de la somme des carr√©s, c'est √† dire la somme de (la diff√©rence entre les valeurs observ√©es et les valeurs pr√©dites) au carr√©. Et v =  est la somme total des carr√©s. Et pour finir, on retourne le rapport de 1-u/v.

```python
def coef_determination (y, pred):
    u=((y - pred)**2).sum()
    v = ((y - y.mean())**2).sum()
    return (1 - (u/v))
```

```python
coef_determination (y, predictions)	
```

```
0.9867144452060398
```

On voit que notre coefficient de d√©termination est de 98,67%. Ce qui est un bon score.
